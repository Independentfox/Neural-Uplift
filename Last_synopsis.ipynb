{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":1610300,"sourceType":"datasetVersion","datasetId":950652}],"dockerImageVersionId":30197,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"* [About this Dataset](#about)\n* [EDA](#eda)\n* [Data preparation](#dataprep)\n* [Modeling](#modeling)\n    * [Meta Learners](#metalearners)\n        * [T-Learners](#tlearners)\n        * [S-Learners](#slearners)\n    * [Uplift Trees](#utrees)\n* [Conclusions](#conclusions)","metadata":{}},{"cell_type":"markdown","source":"# About this Dataset <a class=\"anchor\" id=\"about\"></a>","metadata":{}},{"cell_type":"markdown","source":"  The dataset was created by The Criteo AI Lab .The dataset consists of 13M rows, each one representing a user with 12 features, a treatment indicator and 2 binary labels (visits and conversions). Positive labels mean the user visited/converted on the advertiser website during the test period (2 weeks). The global treatment ratio is 84.6%. It is usual that advertisers keep only a small control population as it costs them in potential revenue.  \n  \nFollowing is a detailed description of the features:  \n  \n- f0, f1, f2, f3, f4, f5, f6, f7, f8, f9, f10, f11: feature values (dense, float)\n- treatment: treatment group (1 = treated, 0 = control)\n- conversion: whether a conversion occured for this user (binary, label)\n- visit: whether a visit occured for this user (binary, label)\n- exposure: treatment effect, whether the user has been effectively exposed (binary)","metadata":{}},{"cell_type":"code","source":"!pip install causalml","metadata":{"execution":{"iopub.status.busy":"2025-04-17T17:25:04.173563Z","iopub.execute_input":"2025-04-17T17:25:04.174692Z","iopub.status.idle":"2025-04-17T17:27:47.928891Z","shell.execute_reply.started":"2025-04-17T17:25:04.174470Z","shell.execute_reply":"2025-04-17T17:27:47.927676Z"},"_kg_hide-output":true,"trusted":true},"outputs":[{"name":"stdout","text":"Collecting causalml\n  Downloading causalml-0.15.2.tar.gz (1.5 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m24.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25h  Installing build dependencies ... \u001b[?25ldone\n\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n\u001b[?25hCollecting pydotplus\n  Downloading pydotplus-2.0.2.tar.gz (278 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m278.7/278.7 kB\u001b[0m \u001b[31m20.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hRequirement already satisfied: tqdm in /opt/conda/lib/python3.7/site-packages (from causalml) (4.64.0)\nRequirement already satisfied: pip>=10.0 in /opt/conda/lib/python3.7/site-packages (from causalml) (22.1)\nRequirement already satisfied: xgboost in /opt/conda/lib/python3.7/site-packages (from causalml) (1.6.1)\nRequirement already satisfied: pathos==0.2.9 in /opt/conda/lib/python3.7/site-packages (from causalml) (0.2.9)\nRequirement already satisfied: lightgbm in /opt/conda/lib/python3.7/site-packages (from causalml) (3.3.2)\nRequirement already satisfied: shap in /opt/conda/lib/python3.7/site-packages (from causalml) (0.40.0)\nRequirement already satisfied: numpy<2,>=1.18.5 in /opt/conda/lib/python3.7/site-packages (from causalml) (1.21.6)\nRequirement already satisfied: Cython<=0.29.34 in /opt/conda/lib/python3.7/site-packages (from causalml) (0.29.30)\nRequirement already satisfied: scikit-learn>=0.22.0 in /opt/conda/lib/python3.7/site-packages (from causalml) (1.0.2)\nCollecting pygam\n  Downloading pygam-0.8.0-py2.py3-none-any.whl (1.8 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m55.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: scipy>=1.4.1 in /opt/conda/lib/python3.7/site-packages (from causalml) (1.7.3)\nRequirement already satisfied: seaborn in /opt/conda/lib/python3.7/site-packages (from causalml) (0.11.2)\nCollecting forestci==0.6\n  Downloading forestci-0.6-py3-none-any.whl (12 kB)\nRequirement already satisfied: packaging in /opt/conda/lib/python3.7/site-packages (from causalml) (21.3)\nRequirement already satisfied: pandas>=0.24.1 in /opt/conda/lib/python3.7/site-packages (from causalml) (1.3.5)\nRequirement already satisfied: statsmodels>=0.9.0 in /opt/conda/lib/python3.7/site-packages (from causalml) (0.13.2)\nRequirement already satisfied: graphviz in /opt/conda/lib/python3.7/site-packages (from causalml) (0.8.4)\nRequirement already satisfied: dill in /opt/conda/lib/python3.7/site-packages (from causalml) (0.3.5.1)\nRequirement already satisfied: matplotlib in /opt/conda/lib/python3.7/site-packages (from causalml) (3.5.2)\nRequirement already satisfied: pox>=0.3.1 in /opt/conda/lib/python3.7/site-packages (from pathos==0.2.9->causalml) (0.3.1)\nRequirement already satisfied: ppft>=1.7.6.5 in /opt/conda/lib/python3.7/site-packages (from pathos==0.2.9->causalml) (1.7.6.5)\nRequirement already satisfied: multiprocess>=0.70.13 in /opt/conda/lib/python3.7/site-packages (from pathos==0.2.9->causalml) (0.70.13)\nRequirement already satisfied: python-dateutil>=2.7.3 in /opt/conda/lib/python3.7/site-packages (from pandas>=0.24.1->causalml) (2.8.2)\nRequirement already satisfied: pytz>=2017.3 in /opt/conda/lib/python3.7/site-packages (from pandas>=0.24.1->causalml) (2022.1)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.7/site-packages (from scikit-learn>=0.22.0->causalml) (3.1.0)\nRequirement already satisfied: joblib>=0.11 in /opt/conda/lib/python3.7/site-packages (from scikit-learn>=0.22.0->causalml) (1.1.0)\nRequirement already satisfied: patsy>=0.5.2 in /opt/conda/lib/python3.7/site-packages (from statsmodels>=0.9.0->causalml) (0.5.2)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.7/site-packages (from packaging->causalml) (3.0.9)\nRequirement already satisfied: wheel in /opt/conda/lib/python3.7/site-packages (from lightgbm->causalml) (0.37.1)\nRequirement already satisfied: pillow>=6.2.0 in /opt/conda/lib/python3.7/site-packages (from matplotlib->causalml) (9.1.0)\nRequirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.7/site-packages (from matplotlib->causalml) (0.11.0)\nRequirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.7/site-packages (from matplotlib->causalml) (1.4.2)\nRequirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.7/site-packages (from matplotlib->causalml) (4.33.3)\nRequirement already satisfied: progressbar2 in /opt/conda/lib/python3.7/site-packages (from pygam->causalml) (4.0.0)\nRequirement already satisfied: future in /opt/conda/lib/python3.7/site-packages (from pygam->causalml) (0.18.2)\nRequirement already satisfied: cloudpickle in /opt/conda/lib/python3.7/site-packages (from shap->causalml) (2.0.0)\nRequirement already satisfied: slicer==0.0.7 in /opt/conda/lib/python3.7/site-packages (from shap->causalml) (0.0.7)\nRequirement already satisfied: numba in /opt/conda/lib/python3.7/site-packages (from shap->causalml) (0.55.1)\nRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.7/site-packages (from kiwisolver>=1.0.1->matplotlib->causalml) (4.2.0)\nRequirement already satisfied: six in /opt/conda/lib/python3.7/site-packages (from patsy>=0.5.2->statsmodels>=0.9.0->causalml) (1.16.0)\nRequirement already satisfied: setuptools in /opt/conda/lib/python3.7/site-packages (from numba->shap->causalml) (59.8.0)\nRequirement already satisfied: llvmlite<0.39,>=0.38.0rc1 in /opt/conda/lib/python3.7/site-packages (from numba->shap->causalml) (0.38.0)\nRequirement already satisfied: python-utils>=3.0.0 in /opt/conda/lib/python3.7/site-packages (from progressbar2->pygam->causalml) (3.2.3)\nBuilding wheels for collected packages: causalml, pydotplus\n  Building wheel for causalml (pyproject.toml) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for causalml: filename=causalml-0.15.2-cp37-cp37m-linux_x86_64.whl size=6428252 sha256=2fb5a4989261f581f908c9b96a0728de1d29e81af238e63d3bd36f144bd833be\n  Stored in directory: /root/.cache/pip/wheels/77/7b/df/ae934d53609fe0cd61502f11c72ed039222b98e08cdebe2a06\n  Building wheel for pydotplus (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for pydotplus: filename=pydotplus-2.0.2-py3-none-any.whl size=24575 sha256=6fac6380e5af7be38b62bc19b0588811e481bfb5e82a4720df885f74f914d027\n  Stored in directory: /root/.cache/pip/wheels/1e/7b/04/7387cf6cc9e48b4a96e361b0be812f0708b394b821bf8c9c50\nSuccessfully built causalml pydotplus\nInstalling collected packages: pydotplus, pygam, forestci, causalml\nSuccessfully installed causalml-0.15.2 forestci-0.6 pydotplus-2.0.2 pygam-0.8.0\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"!pip install scikit-uplift\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-17T17:27:47.931324Z","iopub.execute_input":"2025-04-17T17:27:47.931816Z","iopub.status.idle":"2025-04-17T17:27:58.069888Z","shell.execute_reply.started":"2025-04-17T17:27:47.931766Z","shell.execute_reply":"2025-04-17T17:27:58.068614Z"}},"outputs":[{"name":"stdout","text":"Collecting scikit-uplift\n  Downloading scikit_uplift-0.5.1-py3-none-any.whl (42 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.1/42.1 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: matplotlib in /opt/conda/lib/python3.7/site-packages (from scikit-uplift) (3.5.2)\nRequirement already satisfied: numpy>=1.16 in /opt/conda/lib/python3.7/site-packages (from scikit-uplift) (1.21.6)\nRequirement already satisfied: requests in /opt/conda/lib/python3.7/site-packages (from scikit-uplift) (2.27.1)\nRequirement already satisfied: pandas in /opt/conda/lib/python3.7/site-packages (from scikit-uplift) (1.3.5)\nRequirement already satisfied: scikit-learn>=0.21.0 in /opt/conda/lib/python3.7/site-packages (from scikit-uplift) (1.0.2)\nRequirement already satisfied: tqdm in /opt/conda/lib/python3.7/site-packages (from scikit-uplift) (4.64.0)\nRequirement already satisfied: joblib>=0.11 in /opt/conda/lib/python3.7/site-packages (from scikit-learn>=0.21.0->scikit-uplift) (1.1.0)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.7/site-packages (from scikit-learn>=0.21.0->scikit-uplift) (3.1.0)\nRequirement already satisfied: scipy>=1.1.0 in /opt/conda/lib/python3.7/site-packages (from scikit-learn>=0.21.0->scikit-uplift) (1.7.3)\nRequirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.7/site-packages (from matplotlib->scikit-uplift) (0.11.0)\nRequirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.7/site-packages (from matplotlib->scikit-uplift) (4.33.3)\nRequirement already satisfied: python-dateutil>=2.7 in /opt/conda/lib/python3.7/site-packages (from matplotlib->scikit-uplift) (2.8.2)\nRequirement already satisfied: pyparsing>=2.2.1 in /opt/conda/lib/python3.7/site-packages (from matplotlib->scikit-uplift) (3.0.9)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.7/site-packages (from matplotlib->scikit-uplift) (21.3)\nRequirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.7/site-packages (from matplotlib->scikit-uplift) (1.4.2)\nRequirement already satisfied: pillow>=6.2.0 in /opt/conda/lib/python3.7/site-packages (from matplotlib->scikit-uplift) (9.1.0)\nRequirement already satisfied: pytz>=2017.3 in /opt/conda/lib/python3.7/site-packages (from pandas->scikit-uplift) (2022.1)\nRequirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests->scikit-uplift) (1.26.9)\nRequirement already satisfied: charset-normalizer~=2.0.0 in /opt/conda/lib/python3.7/site-packages (from requests->scikit-uplift) (2.0.12)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests->scikit-uplift) (3.3)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests->scikit-uplift) (2022.5.18.1)\nRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.7/site-packages (from kiwisolver>=1.0.1->matplotlib->scikit-uplift) (4.2.0)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.7/site-packages (from python-dateutil>=2.7->matplotlib->scikit-uplift) (1.16.0)\nInstalling collected packages: scikit-uplift\nSuccessfully installed scikit-uplift-0.5.1\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"%pip install scikit-learn","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-17T17:27:58.071419Z","iopub.execute_input":"2025-04-17T17:27:58.071760Z","iopub.status.idle":"2025-04-17T17:28:07.823665Z","shell.execute_reply.started":"2025-04-17T17:27:58.071725Z","shell.execute_reply":"2025-04-17T17:28:07.822397Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: scikit-learn in /opt/conda/lib/python3.7/site-packages (1.0.2)\nRequirement already satisfied: scipy>=1.1.0 in /opt/conda/lib/python3.7/site-packages (from scikit-learn) (1.7.3)\nRequirement already satisfied: joblib>=0.11 in /opt/conda/lib/python3.7/site-packages (from scikit-learn) (1.1.0)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.7/site-packages (from scikit-learn) (3.1.0)\nRequirement already satisfied: numpy>=1.14.6 in /opt/conda/lib/python3.7/site-packages (from scikit-learn) (1.21.6)\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0mNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.model_selection import train_test_split\nfrom sklift.metrics import uplift_at_k, uplift_auc_score, qini_auc_score, weighted_average_uplift\nfrom sklift.viz import plot_uplift_preds\nfrom sklift.models import SoloModel, TwoModels\nfrom sklearn.base import clone\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import GradientBoostingClassifier, RandomForestClassifier\nfrom lightgbm import LGBMClassifier\nfrom xgboost import XGBClassifier\nfrom causalml.inference.tree import UpliftRandomForestClassifier, UpliftTreeClassifier\nfrom causalml.inference.tree import uplift_tree_string, uplift_tree_plot\nfrom IPython.display import Image","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-17T17:28:07.825901Z","iopub.execute_input":"2025-04-17T17:28:07.826274Z","iopub.status.idle":"2025-04-17T17:28:12.715948Z","shell.execute_reply.started":"2025-04-17T17:28:07.826236Z","shell.execute_reply":"2025-04-17T17:28:12.714931Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<style type='text/css'>\n.datatable table.frame { margin-bottom: 0; }\n.datatable table.frame thead { border-bottom: none; }\n.datatable table.frame tr.coltypes td {  color: #FFFFFF;  line-height: 6px;  padding: 0 0.5em;}\n.datatable .bool    { background: #DDDD99; }\n.datatable .object  { background: #565656; }\n.datatable .int     { background: #5D9E5D; }\n.datatable .float   { background: #4040CC; }\n.datatable .str     { background: #CC4040; }\n.datatable .time    { background: #40CC40; }\n.datatable .row_index {  background: var(--jp-border-color3);  border-right: 1px solid var(--jp-border-color0);  color: var(--jp-ui-font-color3);  font-size: 9px;}\n.datatable .frame tbody td { text-align: left; }\n.datatable .frame tr.coltypes .row_index {  background: var(--jp-border-color0);}\n.datatable th:nth-child(2) { padding-left: 12px; }\n.datatable .hellipsis {  color: var(--jp-cell-editor-border-color);}\n.datatable .vellipsis {  background: var(--jp-layout-color0);  color: var(--jp-cell-editor-border-color);}\n.datatable .na {  color: var(--jp-cell-editor-border-color);  font-size: 80%;}\n.datatable .sp {  opacity: 0.25;}\n.datatable .footer { font-size: 9px; }\n.datatable .frame_dimensions {  background: var(--jp-border-color3);  border-top: 1px solid var(--jp-border-color0);  color: var(--jp-ui-font-color3);  display: inline-block;  opacity: 0.6;  padding: 1px 10px 1px 5px;}\n</style>\n"},"metadata":{}}],"execution_count":4},{"cell_type":"raw","source":"print(\"helk\")","metadata":{}},{"cell_type":"code","source":"print(\"helk\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-17T16:15:11.845837Z","iopub.execute_input":"2025-04-17T16:15:11.846492Z","iopub.status.idle":"2025-04-17T16:15:11.851731Z","shell.execute_reply.started":"2025-04-17T16:15:11.846458Z","shell.execute_reply":"2025-04-17T16:15:11.850623Z"}},"outputs":[{"name":"stdout","text":"helk\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\nimport shap\ndef prepare_data(df, feature_cols, treatment_col='treatment', target_col='conversion', \n                 test_size=0.2, random_state=42):\n    \"\"\"\n    Prepares data for uplift modeling with binary treatment/control setup\n    \"\"\"\n    # Split data into features, treatment and target\n    X = df[feature_cols]\n    y = df[target_col]\n    t = df[treatment_col]\n\n    # Train-test split with stratification on treatment\n    X_train, X_test, t_train, t_test, y_train, y_test = train_test_split(\n        X, t, y, test_size=test_size, random_state=random_state, stratify=t\n    )\n\n    return {\n        't_train': t_train, 't_test': t_test,'X_train': X_train, 'X_test': X_test,'y_train': y_train, 'y_test': y_test\n    }\n\n# Example usage\nfeature_cols = [f'f{i}' for i in range(12)]\ndf = pd.read_csv('../input/uplift-modeling/criteo-uplift-v2.1.csv')\ndata = prepare_data(df, feature_cols)\n\n# Access prepared data\nX_train = data['X_train']\nX_test = data['X_test']\nt_train = data['t_train']\nt_test = data['t_test']\ny_train = data['y_train']\ny_test = data['y_test']\n","metadata":{"execution":{"iopub.status.busy":"2025-04-17T17:28:35.731524Z","iopub.execute_input":"2025-04-17T17:28:35.732208Z","iopub.status.idle":"2025-04-17T17:30:07.047371Z","shell.execute_reply.started":"2025-04-17T17:28:35.732172Z","shell.execute_reply":"2025-04-17T17:30:07.046235Z"},"trusted":true},"outputs":[],"execution_count":5},{"cell_type":"code","source":"from causalml.inference.meta import BaseSRegressor\nfrom causalml.inference.tree import UpliftRandomForestClassifier\nfrom sklearn.multioutput import MultiOutputRegressor\nfrom xgboost import XGBRegressor\n\n\n# Initialize and train S-Learner\nlearner_s = BaseSRegressor(learner=XGBRegressor(random_state=42))\nlearner_s_result = learner_s.fit_predict(X=X_train, treatment=t_train, y=y_train)\n\nprint(learner_s_result)\n","metadata":{"execution":{"iopub.status.busy":"2025-04-17T17:30:07.049353Z","iopub.execute_input":"2025-04-17T17:30:07.049871Z","iopub.status.idle":"2025-04-17T17:32:36.254734Z","shell.execute_reply.started":"2025-04-17T17:30:07.049803Z","shell.execute_reply":"2025-04-17T17:32:36.253174Z"},"trusted":true},"outputs":[{"name":"stdout","text":"[[8.54994287e-05]\n [1.00145233e-04]\n [3.63811385e-03]\n ...\n [1.30322325e-04]\n [8.54995669e-05]\n [1.00145233e-04]]\n","output_type":"stream"}],"execution_count":6},{"cell_type":"code","source":"# from sklearn.utils.validation import check_is_fitted\n# check_is_fitted(learner_s.model)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-17T17:33:43.447114Z","iopub.execute_input":"2025-04-17T17:33:43.448231Z","iopub.status.idle":"2025-04-17T17:33:43.715239Z","shell.execute_reply.started":"2025-04-17T17:33:43.448182Z","shell.execute_reply":"2025-04-17T17:33:43.713598Z"}},"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNotFittedError\u001b[0m                            Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_17/1049859095.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalidation\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcheck_is_fitted\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mcheck_is_fitted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlearner_s\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_is_fitted\u001b[0;34m(estimator, attributes, msg, all_or_any)\u001b[0m\n\u001b[1;32m   1220\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1221\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mfitted\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1222\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mNotFittedError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m\"name\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1223\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1224\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNotFittedError\u001b[0m: This XGBRegressor instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator."],"ename":"NotFittedError","evalue":"This XGBRegressor instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.","output_type":"error"}],"execution_count":7},{"cell_type":"code","source":"# print(type(learner_s.model_tau))  # should be XGBRegressor\n# from sklearn.utils.validation import check_is_fitted\n# check_is_fitted(learner_s.model_tau)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-17T17:35:40.720624Z","iopub.execute_input":"2025-04-17T17:35:40.721811Z","iopub.status.idle":"2025-04-17T17:35:40.754380Z","shell.execute_reply.started":"2025-04-17T17:35:40.721764Z","shell.execute_reply":"2025-04-17T17:35:40.752523Z"}},"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_17/2708840716.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlearner_s\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_tau\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# should be XGBRegressor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalidation\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcheck_is_fitted\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mcheck_is_fitted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlearner_s\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_tau\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mAttributeError\u001b[0m: 'BaseSRegressor' object has no attribute 'model_tau'"],"ename":"AttributeError","evalue":"'BaseSRegressor' object has no attribute 'model_tau'","output_type":"error"}],"execution_count":9},{"cell_type":"code","source":"print(type(learner_s.model))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-17T17:36:03.539941Z","iopub.execute_input":"2025-04-17T17:36:03.541108Z","iopub.status.idle":"2025-04-17T17:36:03.547460Z","shell.execute_reply.started":"2025-04-17T17:36:03.541061Z","shell.execute_reply":"2025-04-17T17:36:03.546305Z"}},"outputs":[{"name":"stdout","text":"<class 'xgboost.sklearn.XGBRegressor'>\n","output_type":"stream"}],"execution_count":10},{"cell_type":"code","source":"# from sklearn.utils.validation import check_is_fitted\n# check_is_fitted(learner_s.model)  # This should now pass ✅\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-17T17:36:38.524468Z","iopub.execute_input":"2025-04-17T17:36:38.524895Z","iopub.status.idle":"2025-04-17T17:36:38.557958Z","shell.execute_reply.started":"2025-04-17T17:36:38.524850Z","shell.execute_reply":"2025-04-17T17:36:38.556507Z"}},"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNotFittedError\u001b[0m                            Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_17/389253072.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalidation\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcheck_is_fitted\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mcheck_is_fitted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlearner_s\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# This should now pass ✅\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_is_fitted\u001b[0;34m(estimator, attributes, msg, all_or_any)\u001b[0m\n\u001b[1;32m   1220\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1221\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mfitted\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1222\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mNotFittedError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m\"name\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1223\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1224\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNotFittedError\u001b[0m: This XGBRegressor instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator."],"ename":"NotFittedError","evalue":"This XGBRegressor instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.","output_type":"error"}],"execution_count":11},{"cell_type":"code","source":"    import shap\n    \n    # 1) Summarize your huge train set into 100 k‑means prototypes\n    background = shap.kmeans(X_train, 100)\n    \n    # 2) Pick 1,000 rows to explain\n    X_explain = X_test.sample(n=1000, random_state=42)\n    \n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-17T17:40:24.511919Z","iopub.execute_input":"2025-04-17T17:40:24.512454Z","iopub.status.idle":"2025-04-17T18:51:30.223233Z","shell.execute_reply.started":"2025-04-17T17:40:24.512417Z","shell.execute_reply":"2025-04-17T18:51:30.221795Z"}},"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_17/1576690893.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;31m# 3) Build the TreeExplainer (exact interventional mode on trees)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m explainer = shap.TreeExplainer(\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0mtau_model\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m     \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbackground\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0mfeature_perturbation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"interventional\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'tau_model' is not defined"],"ename":"NameError","evalue":"name 'tau_model' is not defined","output_type":"error"}],"execution_count":12},{"cell_type":"code","source":"tau_model = learner_s.models[1]  # Key is 1, not 'slearner'\n\n# Now create the SHAP explainer\nexplainer = shap.TreeExplainer(\n    tau_model,\n    data=background,\n    feature_perturbation=\"interventional\"\n)\n\n# Compute SHAP values\nshap_values = explainer.shap_values(X_explain)\n\n# Plot summary\nshap.summary_plot(shap_values, X_explain, feature_names=feature_cols)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-17T19:20:32.581804Z","iopub.execute_input":"2025-04-17T19:20:32.582389Z","iopub.status.idle":"2025-04-17T19:20:32.606881Z","shell.execute_reply.started":"2025-04-17T19:20:32.582344Z","shell.execute_reply":"2025-04-17T19:20:32.605322Z"}},"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_306/568912649.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtau_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlearner_s\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m  \u001b[0;31m# Key is 1, not 'slearner'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# Now create the SHAP explainer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m explainer = shap.TreeExplainer(\n\u001b[1;32m      5\u001b[0m     \u001b[0mtau_model\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'learner_s' is not defined"],"ename":"NameError","evalue":"name 'learner_s' is not defined","output_type":"error"}],"execution_count":2},{"cell_type":"code","source":"# Get SHAP values for your sampled users\nshap_values = explainer.shap_values(X_explain)\n\n# Create detailed contribution DataFrame using feature_cols\nuser_attributions = pd.DataFrame(\n    data=shap_values,\n    columns=[f\"shap_{col}\" for col in feature_cols],\n    index=X_explain.index\n)\n\n# Add metadata columns\nuser_attributions = user_attributions.assign(\n    baseline_prob=explainer.expected_value,\n    predicted_prob=tau_model.predict(X_explain),\n    actual_conversion=y_test.loc[X_explain.index].values if 'conversion' in df.columns else None\n)\n\n# Convert SHAP values to percentage contributions\nshap_abs = np.abs(shap_values)\nuser_attributions_pct = shap_abs / shap_abs.sum(axis=1)[:, np.newaxis]\n\n# Add percentage contribution columns using feature_cols\nfor i, col in enumerate(feature_cols):\n    user_attributions[f\"pct_{col}\"] = user_attributions_pct[:, i]\n\n# Add directional impact labels\nfor col in feature_cols:\n    user_attributions[f\"direction_{col}\"] = np.where(\n        user_attributions[f\"shap_{col}\"] > 0,\n        \"positive\",\n        \"negative\"\n    )\n\n# Reorganize columns\ncolumns_order = ['baseline_prob', 'predicted_prob']\nif 'actual_conversion' in user_attributions:\n    columns_order.append('actual_conversion')\n    \nfor col in feature_cols:\n    columns_order.extend([\n        f\"shap_{col}\",\n        f\"pct_{col}\",\n        f\"direction_{col}\"\n    ])\n\nuser_attributions = user_attributions[columns_order]\n\n# Save to CSV\nuser_attributions.to_csv('user_purchase_decision_contributions.csv')\n\n# Example output for one user\nsample_user = user_attributions.iloc[0]\nprint(f\"\\nPurchase Decision Breakdown for User {sample_user.name}\")\nprint(f\"Baseline Conversion Probability: {sample_user.baseline_prob:.2%}\")\nprint(f\"Predicted Conversion Probability: {sample_user.predicted_prob:.2%}\")\nif 'actual_conversion' in sample_user:\n    print(f\"Actual Conversion: {'Yes' if sample_user.actual_conversion else 'No'}\")\n\nprint(\"\\nFeature Contributions:\")\nfor col in feature_cols:\n    shap_val = sample_user[f\"shap_{col}\"]\n    pct = sample_user[f\"pct_{col}\"]\n    direction = sample_user[f\"direction_{col}\"]\n    \n    if abs(shap_val) > 0.001:  # Filter trivial impacts\n        print(f\"- {col}:\")\n        print(f\"  Contribution: {shap_val:.4f} ({direction})\")\n        print(f\"  Relative Impact: {pct:.1%}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-17T19:20:10.407434Z","iopub.execute_input":"2025-04-17T19:20:10.408100Z","iopub.status.idle":"2025-04-17T19:20:10.506791Z","shell.execute_reply.started":"2025-04-17T19:20:10.407967Z","shell.execute_reply":"2025-04-17T19:20:10.504952Z"}},"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_306/2662478772.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Get SHAP values for your sampled users\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mshap_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexplainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshap_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_explain\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Create detailed contribution DataFrame using feature_cols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m user_attributions = pd.DataFrame(\n","\u001b[0;31mNameError\u001b[0m: name 'explainer' is not defined"],"ename":"NameError","evalue":"name 'explainer' is not defined","output_type":"error"}],"execution_count":1},{"cell_type":"code","source":"# import shap\n\n# background = X_train.sample(n=100, random_state=42)\n\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-17T18:58:04.739112Z","iopub.execute_input":"2025-04-17T18:58:04.739593Z","iopub.status.idle":"2025-04-17T18:58:05.291045Z","shell.execute_reply.started":"2025-04-17T18:58:04.739556Z","shell.execute_reply":"2025-04-17T18:58:05.289905Z"}},"outputs":[],"execution_count":18},{"cell_type":"code","source":"# # This gets the trained XGBRegressor (on treatment + features)\n# tau_model = learner_s.model  # or learner_s.learner depending on causalml version\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-17T18:58:09.329856Z","iopub.execute_input":"2025-04-17T18:58:09.330366Z","iopub.status.idle":"2025-04-17T18:58:09.336044Z","shell.execute_reply.started":"2025-04-17T18:58:09.330323Z","shell.execute_reply":"2025-04-17T18:58:09.334735Z"}},"outputs":[],"execution_count":19},{"cell_type":"code","source":"# import shap\n\n# tau_model = learner_s.model  # this is your trained XGBRegressor\n\n# background = X_train.sample(n=100, random_state=42)  # summarization for SHAP\n\n# explainer = shap.TreeExplainer(tau_model, data=background, feature_perturbation=\"interventional\")\n# shap_values = explainer.shap_values(X_explain)\n\n# shap.summary_plot(shap_values, X_explain, feature_names=feature_cols)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-17T19:00:21.228881Z","iopub.execute_input":"2025-04-17T19:00:21.229291Z","iopub.status.idle":"2025-04-17T19:00:21.947632Z","shell.execute_reply.started":"2025-04-17T19:00:21.229259Z","shell.execute_reply":"2025-04-17T19:00:21.946154Z"}},"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNotFittedError\u001b[0m                            Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_17/2104412972.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mbackground\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m42\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# summarization for SHAP\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mexplainer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mshap\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTreeExplainer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtau_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbackground\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeature_perturbation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"interventional\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0mshap_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexplainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshap_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_explain\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/shap/explainers/_tree.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, model, data, model_output, feature_perturbation, feature_names, approximate, **deprecated_options)\u001b[0m\n\u001b[1;32m    146\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeature_perturbation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfeature_perturbation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    147\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpected_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 148\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTreeEnsemble\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_missing\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    149\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    150\u001b[0m         \u001b[0;31m#self.model_output = self.model.model_output # this allows the TreeEnsemble to translate model outputs types by how it loads the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/shap/explainers/_tree.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, model, data, data_missing, model_output)\u001b[0m\n\u001b[1;32m    841\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0msafe_isinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"xgboost.sklearn.XGBRegressor\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    842\u001b[0m             \u001b[0;32mimport\u001b[0m \u001b[0mxgboost\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 843\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moriginal_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_booster\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    844\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_type\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"xgboost\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    845\u001b[0m             \u001b[0mxgb_loader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mXGBTreeModelLoader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moriginal_model\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/xgboost/sklearn.py\u001b[0m in \u001b[0;36mget_booster\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    588\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__sklearn_is_fitted__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    589\u001b[0m             \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexceptions\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mNotFittedError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 590\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mNotFittedError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'need to call fit or load_model beforehand'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    591\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_Booster\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    592\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNotFittedError\u001b[0m: need to call fit or load_model beforehand"],"ename":"NotFittedError","evalue":"need to call fit or load_model beforehand","output_type":"error"}],"execution_count":24},{"cell_type":"code","source":"# explainer = shap.TreeExplainer(\n#     tau_model,\n#     data=background,\n#     feature_perturbation=\"interventional\"\n# )\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-17T18:58:11.339955Z","iopub.execute_input":"2025-04-17T18:58:11.341189Z","iopub.status.idle":"2025-04-17T18:58:11.372199Z","shell.execute_reply.started":"2025-04-17T18:58:11.341145Z","shell.execute_reply":"2025-04-17T18:58:11.370584Z"}},"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNotFittedError\u001b[0m                            Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_17/3147235970.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mtau_model\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbackground\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mfeature_perturbation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"interventional\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m )\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/shap/explainers/_tree.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, model, data, model_output, feature_perturbation, feature_names, approximate, **deprecated_options)\u001b[0m\n\u001b[1;32m    146\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeature_perturbation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfeature_perturbation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    147\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpected_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 148\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTreeEnsemble\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_missing\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    149\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    150\u001b[0m         \u001b[0;31m#self.model_output = self.model.model_output # this allows the TreeEnsemble to translate model outputs types by how it loads the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/shap/explainers/_tree.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, model, data, data_missing, model_output)\u001b[0m\n\u001b[1;32m    841\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0msafe_isinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"xgboost.sklearn.XGBRegressor\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    842\u001b[0m             \u001b[0;32mimport\u001b[0m \u001b[0mxgboost\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 843\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moriginal_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_booster\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    844\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_type\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"xgboost\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    845\u001b[0m             \u001b[0mxgb_loader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mXGBTreeModelLoader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moriginal_model\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/xgboost/sklearn.py\u001b[0m in \u001b[0;36mget_booster\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    588\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__sklearn_is_fitted__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    589\u001b[0m             \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexceptions\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mNotFittedError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 590\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mNotFittedError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'need to call fit or load_model beforehand'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    591\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_Booster\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    592\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNotFittedError\u001b[0m: need to call fit or load_model beforehand"],"ename":"NotFittedError","evalue":"need to call fit or load_model beforehand","output_type":"error"}],"execution_count":20},{"cell_type":"code","source":"# # 2) Pick fewer rows for explanation\n# X_explain = X_test.sample(300, random_state=42)\n\n# # 3) Enable approximate mode to speed up TreeExplainer\n# explainer = shap.TreeExplainer(\n#     learner_s,\n#     data=background,\n#     feature_perturbation=\"interventional\",\n#     approximate=True\n# )\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-17T18:56:36.302947Z","iopub.execute_input":"2025-04-17T18:56:36.303485Z","iopub.status.idle":"2025-04-17T18:56:36.514143Z","shell.execute_reply.started":"2025-04-17T18:56:36.303443Z","shell.execute_reply":"2025-04-17T18:56:36.512804Z"}},"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mException\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_17/94709347.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbackground\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mfeature_perturbation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"interventional\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0mapproximate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m )\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/shap/explainers/_tree.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, model, data, model_output, feature_perturbation, feature_names, approximate, **deprecated_options)\u001b[0m\n\u001b[1;32m    103\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmasker\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mmasker\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 105\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Unsupported masker type: %s!\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmasker\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    106\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmasker\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"clustering\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mException\u001b[0m: Unsupported masker type: <class 'shap.utils._legacy.DenseData'>!"],"ename":"Exception","evalue":"Unsupported masker type: <class 'shap.utils._legacy.DenseData'>!","output_type":"error"}],"execution_count":15},{"cell_type":"code","source":"\n# # 4) Compute SHAP values\n# shap_values = explainer.shap_values(X_explain)\n\n# # 5) Plot summary\n# shap.summary_plot(shap_values, X_explain, feature_names=feature_cols)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-17T18:55:10.528392Z","iopub.execute_input":"2025-04-17T18:55:10.529051Z","iopub.status.idle":"2025-04-17T18:55:10.564975Z","shell.execute_reply.started":"2025-04-17T18:55:10.529002Z","shell.execute_reply":"2025-04-17T18:55:10.563546Z"}},"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_17/1493202787.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# 4) Compute SHAP values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mshap_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexplainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshap_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_explain\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# 5) Plot summary\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mshap\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary_plot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshap_values\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_explain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeature_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeature_cols\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'explainer' is not defined"],"ename":"NameError","evalue":"name 'explainer' is not defined","output_type":"error"}],"execution_count":13},{"cell_type":"code","source":"# # Suppose your treatments are 0 and 1\n# for t_val, mdl in learner_s.models.items():\n#     print(f\"Booster for treatment={t_val}:\", mdl.get_booster())\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-17T16:41:03.411695Z","iopub.execute_input":"2025-04-17T16:41:03.413185Z","iopub.status.idle":"2025-04-17T16:41:03.420315Z","shell.execute_reply.started":"2025-04-17T16:41:03.413123Z","shell.execute_reply":"2025-04-17T16:41:03.418559Z"}},"outputs":[{"name":"stdout","text":"Booster for treatment=1: <xgboost.core.Booster object at 0x78f4d849afd0>\n","output_type":"stream"}],"execution_count":31},{"cell_type":"code","source":"# # 'weight' is the number of times a feature appears in a split\n# importance = booster.get_score(importance_type='weight')\n# print(importance)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-17T16:41:43.803324Z","iopub.execute_input":"2025-04-17T16:41:43.803794Z","iopub.status.idle":"2025-04-17T16:41:43.810570Z","shell.execute_reply.started":"2025-04-17T16:41:43.803758Z","shell.execute_reply":"2025-04-17T16:41:43.809456Z"}},"outputs":[{"name":"stdout","text":"{'f0': 119.0, 'f1': 545.0, 'f2': 237.0, 'f3': 578.0, 'f4': 401.0, 'f5': 808.0, 'f6': 287.0, 'f7': 298.0, 'f8': 319.0, 'f9': 272.0, 'f10': 425.0, 'f11': 565.0, 'f12': 477.0}\n","output_type":"stream"}],"execution_count":32},{"cell_type":"code","source":"# print(learner_s.model)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-17T16:58:53.554065Z","iopub.execute_input":"2025-04-17T16:58:53.555577Z","iopub.status.idle":"2025-04-17T16:58:53.563795Z","shell.execute_reply.started":"2025-04-17T16:58:53.555528Z","shell.execute_reply":"2025-04-17T16:58:53.562586Z"}},"outputs":[{"name":"stdout","text":"XGBRegressor(base_score=None, booster=None, callbacks=None,\n             colsample_bylevel=None, colsample_bynode=None,\n             colsample_bytree=None, early_stopping_rounds=None,\n             enable_categorical=False, eval_metric=None, gamma=None,\n             gpu_id=None, grow_policy=None, importance_type=None,\n             interaction_constraints=None, learning_rate=None, max_bin=None,\n             max_cat_to_onehot=None, max_delta_step=None, max_depth=None,\n             max_leaves=None, min_child_weight=None, missing=nan,\n             monotone_constraints=None, n_estimators=100, n_jobs=None,\n             num_parallel_tree=None, predictor=None, random_state=42,\n             reg_alpha=None, reg_lambda=None, ...)\n","output_type":"stream"}],"execution_count":40},{"cell_type":"code","source":"# import numpy as np\n# import pandas as pd\n# import shap\n\n# # --- assume learner_s is already fitted via fit_predict() ---\n# #   and that X is your full feature DataFrame\n\n# # 1. Grab the two fitted base models\n# model_c = learner_s.models[0]   # control\n# model_t = learner_s.models[1]   # treated\n\n# # 2. Full‐data predictions & ITE point estimates\n# pred_c = model_c.predict(X)\n# pred_t = model_t.predict(X)\n# ite_pred = pred_t - pred_c\n\n# df_ite = pd.DataFrame({\n#     'pred_control': pred_c,\n#     'pred_treated': pred_t,\n#     'ite_pred': ite_pred\n# }, index=X.index)\n\n# # 3. Sample ~10 000 users for SHAP\n# sample_size = min(10_000, len(X))\n# sample_idx = np.random.choice(X.index, size=sample_size, replace=False)\n# X_sample = X.loc[sample_idx]\n\n# # 4. Build TreeExplainers on the raw boosters\n# booster_c = model_c.get_booster()\n# booster_t = model_t.get_booster()\n# expl_c   = shap.TreeExplainer(booster_c)\n# expl_t   = shap.TreeExplainer(booster_t)\n\n# # 5. Compute SHAP values on the sample\n# shap_c = expl_c.shap_values(X_sample)   # (sample_size, n_features)\n# shap_t = expl_t.shap_values(X_sample)   # same shape\n\n# # 6. Compute per‐feature contribution to uplift = difference of SHAPs\n# ite_shap = shap_t - shap_c              # (sample_size, n_features)\n# shap_cols = [f\"ΔSHAP_{col}\" for col in X.columns]\n# df_shap_sample = pd.DataFrame(ite_shap, columns=shap_cols, index=sample_idx)\n\n# # 7. Map those sample‐level contributions back to full cohort\n# #    (off‐sample rows will be NaN)\n# df_shap_all = pd.DataFrame(index=X.index, columns=shap_cols)\n# df_shap_all.loc[sample_idx] = df_shap_sample\n\n# # 8. Combine predictions + contributions\n# df_result = pd.concat([df_ite, df_shap_all], axis=1)\n\n# # — now:\n# # df_result.loc[user_id, 'ite_pred']          → ITE estimate for that user\n# # df_result.loc[user_id, shap_cols]           → feature‐level ITE contributions (or NaN)\n# # df_result.sample(5)                         → peek at 5 random users\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-17T16:59:07.097236Z","iopub.execute_input":"2025-04-17T16:59:07.097802Z","iopub.status.idle":"2025-04-17T16:59:07.155430Z","shell.execute_reply.started":"2025-04-17T16:59:07.097750Z","shell.execute_reply":"2025-04-17T16:59:07.153968Z"}},"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_17/962994186.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m# 1. Grab the two fitted base models\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mmodel_c\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlearner_s\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m   \u001b[0;31m# control\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0mmodel_t\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlearner_s\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m   \u001b[0;31m# treated\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyError\u001b[0m: 0"],"ename":"KeyError","evalue":"0","output_type":"error"}],"execution_count":41},{"cell_type":"code","source":"print(\"Available treatment groups:\", learner_s.t_groups)\nprint(\"Keys in learner_s.models:\", learner_s.models.keys())\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-17T16:59:15.304935Z","iopub.execute_input":"2025-04-17T16:59:15.305371Z","iopub.status.idle":"2025-04-17T16:59:15.311786Z","shell.execute_reply.started":"2025-04-17T16:59:15.305336Z","shell.execute_reply":"2025-04-17T16:59:15.310636Z"}},"outputs":[{"name":"stdout","text":"Available treatment groups: [1]\nKeys in learner_s.models: dict_keys([1])\n","output_type":"stream"}],"execution_count":42},{"cell_type":"code","source":"# import numpy as np\n# print(\"Unique treatments in t_train:\", np.unique(t_train))\n# print(\"Counts:\\n\", pd.Series(t_train).value_counts())\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-17T16:45:14.999564Z","iopub.execute_input":"2025-04-17T16:45:15.000043Z","iopub.status.idle":"2025-04-17T16:45:15.389375Z","shell.execute_reply.started":"2025-04-17T16:45:15.000004Z","shell.execute_reply":"2025-04-17T16:45:15.388243Z"}},"outputs":[{"name":"stdout","text":"Unique treatments in t_train: [0 1]\nCounts:\n 1    9506123\n0    1677550\nName: treatment, dtype: int64\n","output_type":"stream"}],"execution_count":35},{"cell_type":"code","source":"# from causalml.inference.meta import BaseSRegressor\n# from xgboost import XGBRegressor\n\n# # Recreate the S-learner and explicitly fit it\n# learner_s = BaseSRegressor(learner=XGBRegressor(random_state=42))\n# learner_s.fit(X=X_train, treatment=t_train, y=y_train)\n\n# # Now it’s safe to access the fitted model\n# model = learner_s.model","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-17T16:50:20.414458Z","iopub.execute_input":"2025-04-17T16:50:20.414973Z","iopub.status.idle":"2025-04-17T16:52:21.950992Z","shell.execute_reply.started":"2025-04-17T16:50:20.414935Z","shell.execute_reply":"2025-04-17T16:52:21.949835Z"}},"outputs":[],"execution_count":38},{"cell_type":"code","source":"# import numpy as np\n# import pandas as pd\n# import shap\n# import matplotlib.pyplot as plt\n\n# # 1. Access the trained model (only treatment=1 exists in .models because BaseSRegressor uses one model with treatment as feature)\n# model = learner_s.model  # This is your XGBRegressor\n\n# # 2. Compute ITEs on full data\n# X_np = X_train.values if hasattr(X_train, \"values\") else X_train\n# n, p = X_np.shape\n\n# # Create copies of X with treatment=0 and treatment=1 as first column\n# X_control = np.hstack((np.zeros((n, 1)), X_np))\n# X_treat   = np.hstack((np.ones((n, 1)),  X_np))\n\n# # Predict outcomes\n# pred_c   = model.predict(X_control)\n# pred_t   = model.predict(X_treat)\n# ite_pred = pred_t - pred_c\n\n# # Create DataFrame with ITE\n# df_result = pd.DataFrame({\n#     \"pred_control\": pred_c,\n#     \"pred_treated\": pred_t,\n#     \"ite_pred\":     ite_pred\n# }, index=X_train.index)\n\n# # 3. SHAP value estimation on a small sample\n# sample_size = 10000  # You can adjust this\n# sample_idx = np.random.choice(X_train.index, size=sample_size, replace=False)\n# X_samp = X_train.loc[sample_idx]\n\n# # Add treatment column to features\n# Xt_samp = np.hstack((np.ones((sample_size, 1)), X_samp.values))  # treatment = 1\n# Xc_samp = np.hstack((np.zeros((sample_size, 1)), X_samp.values)) # treatment = 0\n\n# # Create SHAP explainer\n# explainer = shap.TreeExplainer(model)\n\n# # Compute SHAP values for treatment=1 and treatment=0\n# shap_treated = explainer.shap_values(Xt_samp)\n# shap_control = explainer.shap_values(Xc_samp)\n\n# # Compute SHAP uplift (difference in contribution)\n# shap_uplift = shap_treated - shap_control\n\n# # Create SHAP DataFrame for the sample\n# shap_df = pd.DataFrame(shap_uplift, columns=X_train.columns, index=X_samp.index)\n# shap_df[\"ite_pred_sample\"] = ite_pred[sample_idx]\n\n# # 4. Summary plot of feature contributions to ITE\n# shap.summary_plot(shap_uplift, features=X_samp, feature_names=X_train.columns, show=True)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-17T16:59:51.755595Z","iopub.execute_input":"2025-04-17T16:59:51.756083Z","iopub.status.idle":"2025-04-17T16:59:53.320144Z","shell.execute_reply.started":"2025-04-17T16:59:51.756033Z","shell.execute_reply":"2025-04-17T16:59:53.318846Z"}},"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNotFittedError\u001b[0m                            Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_17/3030153802.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;31m# Predict outcomes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m \u001b[0mpred_c\u001b[0m   \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_control\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0mpred_t\u001b[0m   \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_treat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0mite_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpred_t\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mpred_c\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/xgboost/sklearn.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X, output_margin, ntree_limit, validate_features, base_margin, iteration_range)\u001b[0m\n\u001b[1;32m   1042\u001b[0m         \"\"\"\n\u001b[1;32m   1043\u001b[0m         iteration_range = _convert_ntree_limit(\n\u001b[0;32m-> 1044\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_booster\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mntree_limit\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miteration_range\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1045\u001b[0m         )\n\u001b[1;32m   1046\u001b[0m         \u001b[0miteration_range\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_iteration_range\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miteration_range\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/xgboost/sklearn.py\u001b[0m in \u001b[0;36mget_booster\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    588\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__sklearn_is_fitted__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    589\u001b[0m             \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexceptions\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mNotFittedError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 590\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mNotFittedError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'need to call fit or load_model beforehand'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    591\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_Booster\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    592\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNotFittedError\u001b[0m: need to call fit or load_model beforehand"],"ename":"NotFittedError","evalue":"need to call fit or load_model beforehand","output_type":"error"}],"execution_count":43},{"cell_type":"code","source":"# fitted_model = learner_s.models['slearner']\n# print(fitted_model.get_booster())  \n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-17T17:00:04.612099Z","iopub.execute_input":"2025-04-17T17:00:04.613219Z","iopub.status.idle":"2025-04-17T17:00:04.637744Z","shell.execute_reply.started":"2025-04-17T17:00:04.613175Z","shell.execute_reply":"2025-04-17T17:00:04.636225Z"}},"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_17/3929132934.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mfitted_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlearner_s\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'slearner'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfitted_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_booster\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyError\u001b[0m: 'slearner'"],"ename":"KeyError","evalue":"'slearner'","output_type":"error"}],"execution_count":44},{"cell_type":"code","source":"# # This will explicitly fit your S-learner model (XGBoost inside)\n# learner_s.fit(X=X_train, treatment=t_train, y=y_train)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-17T16:27:44.004130Z","iopub.execute_input":"2025-04-17T16:27:44.004540Z","iopub.status.idle":"2025-04-17T16:29:42.731809Z","shell.execute_reply.started":"2025-04-17T16:27:44.004511Z","shell.execute_reply":"2025-04-17T16:29:42.730690Z"}},"outputs":[],"execution_count":20},{"cell_type":"code","source":"print(learner_s.model)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-17T17:18:46.621284Z","iopub.execute_input":"2025-04-17T17:18:46.621703Z","iopub.status.idle":"2025-04-17T17:18:46.628568Z","shell.execute_reply.started":"2025-04-17T17:18:46.621674Z","shell.execute_reply":"2025-04-17T17:18:46.627520Z"}},"outputs":[{"name":"stdout","text":"XGBRegressor(base_score=None, booster=None, callbacks=None,\n             colsample_bylevel=None, colsample_bynode=None,\n             colsample_bytree=None, early_stopping_rounds=None,\n             enable_categorical=False, eval_metric=None, gamma=None,\n             gpu_id=None, grow_policy=None, importance_type=None,\n             interaction_constraints=None, learning_rate=None, max_bin=None,\n             max_cat_to_onehot=None, max_delta_step=None, max_depth=None,\n             max_leaves=None, min_child_weight=None, missing=nan,\n             monotone_constraints=None, n_estimators=100, n_jobs=None,\n             num_parallel_tree=None, predictor=None, random_state=42,\n             reg_alpha=None, reg_lambda=None, ...)\n","output_type":"stream"}],"execution_count":59},{"cell_type":"code","source":"# fitted_model = learner_s.model\n# print(fitted_model.get_booster())\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-17T16:30:37.796586Z","iopub.execute_input":"2025-04-17T16:30:37.797163Z","iopub.status.idle":"2025-04-17T16:30:37.827826Z","shell.execute_reply.started":"2025-04-17T16:30:37.797116Z","shell.execute_reply":"2025-04-17T16:30:37.826353Z"}},"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNotFittedError\u001b[0m                            Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_17/2027570563.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mfitted_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlearner_s\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfitted_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_booster\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/xgboost/sklearn.py\u001b[0m in \u001b[0;36mget_booster\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    588\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__sklearn_is_fitted__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    589\u001b[0m             \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexceptions\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mNotFittedError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 590\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mNotFittedError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'need to call fit or load_model beforehand'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    591\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_Booster\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    592\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNotFittedError\u001b[0m: need to call fit or load_model beforehand"],"ename":"NotFittedError","evalue":"need to call fit or load_model beforehand","output_type":"error"}],"execution_count":24},{"cell_type":"code","source":"print(dir(learner_s))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-17T17:08:30.545501Z","iopub.execute_input":"2025-04-17T17:08:30.546030Z","iopub.status.idle":"2025-04-17T17:08:30.552083Z","shell.execute_reply.started":"2025-04-17T17:08:30.545993Z","shell.execute_reply":"2025-04-17T17:08:30.550867Z"}},"outputs":[{"name":"stdout","text":"['__abstractmethods__', '__class__', '__delattr__', '__dict__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__le__', '__lt__', '__module__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__sizeof__', '__str__', '__subclasshook__', '__weakref__', '_abc_impl', '_classes', '_format_p', '_set_propensity_models', 'ate_alpha', 'bootstrap', 'control_name', 'estimate_ate', 'fit', 'fit_predict', 'get_importance', 'get_shap_values', 'model', 'models', 'plot_importance', 'plot_shap_dependence', 'plot_shap_values', 'predict', 't_groups']\n","output_type":"stream"}],"execution_count":45},{"cell_type":"code","source":"print(dir(learner_s))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-17T16:35:09.568515Z","iopub.execute_input":"2025-04-17T16:35:09.569167Z","iopub.status.idle":"2025-04-17T16:35:09.576610Z","shell.execute_reply.started":"2025-04-17T16:35:09.569121Z","shell.execute_reply":"2025-04-17T16:35:09.575189Z"}},"outputs":[{"name":"stdout","text":"['__abstractmethods__', '__class__', '__delattr__', '__dict__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__le__', '__lt__', '__module__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__sizeof__', '__str__', '__subclasshook__', '__weakref__', '_abc_impl', '_classes', '_format_p', '_set_propensity_models', 'ate_alpha', 'bootstrap', 'control_name', 'estimate_ate', 'fit', 'fit_predict', 'get_importance', 'get_shap_values', 'model', 'models', 'plot_importance', 'plot_shap_dependence', 'plot_shap_values', 'predict', 't_groups']\n","output_type":"stream"}],"execution_count":26},{"cell_type":"code","source":"print(type(learner_s.model))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-17T17:08:37.509998Z","iopub.execute_input":"2025-04-17T17:08:37.511146Z","iopub.status.idle":"2025-04-17T17:08:37.516922Z","shell.execute_reply.started":"2025-04-17T17:08:37.511090Z","shell.execute_reply":"2025-04-17T17:08:37.515897Z"}},"outputs":[{"name":"stdout","text":"<class 'xgboost.sklearn.XGBRegressor'>\n","output_type":"stream"}],"execution_count":46},{"cell_type":"code","source":"# fitted_model = learner_s.model\n# print(fitted_model.get_booster())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-17T16:25:17.909396Z","iopub.execute_input":"2025-04-17T16:25:17.909839Z","iopub.status.idle":"2025-04-17T16:25:17.937532Z","shell.execute_reply.started":"2025-04-17T16:25:17.909804Z","shell.execute_reply":"2025-04-17T16:25:17.936277Z"}},"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNotFittedError\u001b[0m                            Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_17/3835034498.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mfitted_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlearner_s\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfitted_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_booster\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/xgboost/sklearn.py\u001b[0m in \u001b[0;36mget_booster\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    588\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__sklearn_is_fitted__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    589\u001b[0m             \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexceptions\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mNotFittedError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 590\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mNotFittedError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'need to call fit or load_model beforehand'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    591\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_Booster\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    592\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNotFittedError\u001b[0m: need to call fit or load_model beforehand"],"ename":"NotFittedError","evalue":"need to call fit or load_model beforehand","output_type":"error"}],"execution_count":13},{"cell_type":"code","source":"print(learner_s_result.shape)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-17T17:08:43.779468Z","iopub.execute_input":"2025-04-17T17:08:43.780210Z","iopub.status.idle":"2025-04-17T17:08:43.786046Z","shell.execute_reply.started":"2025-04-17T17:08:43.780171Z","shell.execute_reply":"2025-04-17T17:08:43.784871Z"}},"outputs":[{"name":"stdout","text":"(11183673, 1)\n","output_type":"stream"}],"execution_count":47},{"cell_type":"code","source":"result=learner_s.get_importance(X=X_train, tau=learner_s_result, normalize=True, method='auto', features=feature_cols)\nresult","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-17T17:08:49.053020Z","iopub.execute_input":"2025-04-17T17:08:49.053442Z","iopub.status.idle":"2025-04-17T17:09:15.187099Z","shell.execute_reply.started":"2025-04-17T17:08:49.053408Z","shell.execute_reply":"2025-04-17T17:09:15.186008Z"}},"outputs":[{"execution_count":48,"output_type":"execute_result","data":{"text/plain":"{1: f4     0.446077\n f3     0.194586\n f11    0.087215\n f9     0.065065\n f0     0.056892\n f2     0.044279\n f10    0.037780\n f6     0.028997\n f8     0.013343\n f5     0.010116\n f7     0.008173\n f1     0.007478\n dtype: float64}"},"metadata":{}}],"execution_count":48},{"cell_type":"code","source":"print(learner_s.models)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-17T17:09:15.188779Z","iopub.execute_input":"2025-04-17T17:09:15.189182Z","iopub.status.idle":"2025-04-17T17:09:15.200253Z","shell.execute_reply.started":"2025-04-17T17:09:15.189148Z","shell.execute_reply":"2025-04-17T17:09:15.198995Z"}},"outputs":[{"name":"stdout","text":"{1: XGBRegressor(base_score=0.5, booster='gbtree', callbacks=None,\n             colsample_bylevel=1, colsample_bynode=1, colsample_bytree=1,\n             early_stopping_rounds=None, enable_categorical=False,\n             eval_metric=None, gamma=0, gpu_id=-1, grow_policy='depthwise',\n             importance_type=None, interaction_constraints='',\n             learning_rate=0.300000012, max_bin=256, max_cat_to_onehot=4,\n             max_delta_step=0, max_depth=6, max_leaves=0, min_child_weight=1,\n             missing=nan, monotone_constraints='()', n_estimators=100, n_jobs=0,\n             num_parallel_tree=1, predictor='auto', random_state=42,\n             reg_alpha=0, reg_lambda=1, ...)}\n","output_type":"stream"}],"execution_count":49},{"cell_type":"code","source":"print(type(learner_s.model))  # Inspect the type","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-17T16:26:33.016853Z","iopub.execute_input":"2025-04-17T16:26:33.017806Z","iopub.status.idle":"2025-04-17T16:26:33.022784Z","shell.execute_reply.started":"2025-04-17T16:26:33.017769Z","shell.execute_reply":"2025-04-17T16:26:33.021736Z"}},"outputs":[{"name":"stdout","text":"<class 'xgboost.sklearn.XGBRegressor'>\n","output_type":"stream"}],"execution_count":16},{"cell_type":"code","source":"# fitted_model = learner_s.model\n# print(fitted_model.get_booster())\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-17T17:09:41.900752Z","iopub.execute_input":"2025-04-17T17:09:41.901227Z","iopub.status.idle":"2025-04-17T17:09:41.930313Z","shell.execute_reply.started":"2025-04-17T17:09:41.901193Z","shell.execute_reply":"2025-04-17T17:09:41.929027Z"}},"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNotFittedError\u001b[0m                            Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_17/2027570563.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mfitted_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlearner_s\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfitted_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_booster\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/xgboost/sklearn.py\u001b[0m in \u001b[0;36mget_booster\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    588\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__sklearn_is_fitted__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    589\u001b[0m             \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexceptions\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mNotFittedError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 590\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mNotFittedError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'need to call fit or load_model beforehand'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    591\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_Booster\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    592\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNotFittedError\u001b[0m: need to call fit or load_model beforehand"],"ename":"NotFittedError","evalue":"need to call fit or load_model beforehand","output_type":"error"}],"execution_count":50},{"cell_type":"code","source":"# from xgboost import XGBRegressor\n\n# # Create your own XGBRegressor\n# xgb_model = XGBRegressor(random_state=42)\n\n# # Create treatment indicator feature\n# X_augmented = X_train.copy()\n# X_augmented['treatment'] = t_train\n\n# # Fit the model directly on augmented X and original y\n# xgb_model.fit(X_augmented, y_train)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-17T16:18:52.823978Z","iopub.status.idle":"2025-04-17T16:18:52.824513Z","shell.execute_reply.started":"2025-04-17T16:18:52.824254Z","shell.execute_reply":"2025-04-17T16:18:52.824280Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# learner_s.fit(X=X_train, treatment=t_train, y=y_train)\n\n# # Verify that the model has been fitted\n# print(learner_s.model.get_booster())\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-17T17:19:20.504445Z","iopub.execute_input":"2025-04-17T17:19:20.504958Z","iopub.status.idle":"2025-04-17T17:21:22.166334Z","shell.execute_reply.started":"2025-04-17T17:19:20.504921Z","shell.execute_reply":"2025-04-17T17:21:22.164749Z"}},"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNotFittedError\u001b[0m                            Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_17/3373013277.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# Verify that the model has been fitted\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlearner_s\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_booster\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/xgboost/sklearn.py\u001b[0m in \u001b[0;36mget_booster\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    588\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__sklearn_is_fitted__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    589\u001b[0m             \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexceptions\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mNotFittedError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 590\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mNotFittedError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'need to call fit or load_model beforehand'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    591\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_Booster\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    592\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNotFittedError\u001b[0m: need to call fit or load_model beforehand"],"ename":"NotFittedError","evalue":"need to call fit or load_model beforehand","output_type":"error"}],"execution_count":60},{"cell_type":"code","source":"# from sklearn.utils.validation import check_is_fitted\n\n# check_is_fitted(learner_s.model)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-17T17:23:13.309312Z","iopub.execute_input":"2025-04-17T17:23:13.309768Z","iopub.status.idle":"2025-04-17T17:23:13.338553Z","shell.execute_reply.started":"2025-04-17T17:23:13.309732Z","shell.execute_reply":"2025-04-17T17:23:13.337198Z"}},"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNotFittedError\u001b[0m                            Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_17/1783174979.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalidation\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcheck_is_fitted\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mcheck_is_fitted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlearner_s\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_is_fitted\u001b[0;34m(estimator, attributes, msg, all_or_any)\u001b[0m\n\u001b[1;32m   1220\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1221\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mfitted\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1222\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mNotFittedError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m\"name\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1223\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1224\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNotFittedError\u001b[0m: This XGBRegressor instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator."],"ename":"NotFittedError","evalue":"This XGBRegressor instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.","output_type":"error"}],"execution_count":62},{"cell_type":"code","source":"# print(learner_s.model.get_booster())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-17T17:21:42.153801Z","iopub.execute_input":"2025-04-17T17:21:42.154764Z","iopub.status.idle":"2025-04-17T17:21:42.177750Z","shell.execute_reply.started":"2025-04-17T17:21:42.154721Z","shell.execute_reply":"2025-04-17T17:21:42.176507Z"}},"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNotFittedError\u001b[0m                            Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_17/4251629637.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlearner_s\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_booster\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/xgboost/sklearn.py\u001b[0m in \u001b[0;36mget_booster\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    588\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__sklearn_is_fitted__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    589\u001b[0m             \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexceptions\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mNotFittedError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 590\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mNotFittedError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'need to call fit or load_model beforehand'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    591\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_Booster\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    592\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNotFittedError\u001b[0m: need to call fit or load_model beforehand"],"ename":"NotFittedError","evalue":"need to call fit or load_model beforehand","output_type":"error"}],"execution_count":61},{"cell_type":"code","source":"pip install --upgrade shap\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-17T17:10:01.630021Z","iopub.execute_input":"2025-04-17T17:10:01.630467Z","iopub.status.idle":"2025-04-17T17:10:12.744318Z","shell.execute_reply.started":"2025-04-17T17:10:01.630437Z","shell.execute_reply":"2025-04-17T17:10:12.743060Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: shap in /opt/conda/lib/python3.7/site-packages (0.40.0)\nCollecting shap\n  Downloading shap-0.42.1-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (545 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m545.7/545.7 kB\u001b[0m \u001b[31m18.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: numpy in /opt/conda/lib/python3.7/site-packages (from shap) (1.21.6)\nRequirement already satisfied: packaging>20.9 in /opt/conda/lib/python3.7/site-packages (from shap) (21.3)\nRequirement already satisfied: cloudpickle in /opt/conda/lib/python3.7/site-packages (from shap) (2.0.0)\nRequirement already satisfied: numba in /opt/conda/lib/python3.7/site-packages (from shap) (0.55.1)\nRequirement already satisfied: scikit-learn in /opt/conda/lib/python3.7/site-packages (from shap) (1.0.2)\nRequirement already satisfied: slicer==0.0.7 in /opt/conda/lib/python3.7/site-packages (from shap) (0.0.7)\nRequirement already satisfied: scipy in /opt/conda/lib/python3.7/site-packages (from shap) (1.7.3)\nRequirement already satisfied: tqdm>=4.27.0 in /opt/conda/lib/python3.7/site-packages (from shap) (4.64.0)\nRequirement already satisfied: pandas in /opt/conda/lib/python3.7/site-packages (from shap) (1.3.5)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.7/site-packages (from packaging>20.9->shap) (3.0.9)\nRequirement already satisfied: setuptools in /opt/conda/lib/python3.7/site-packages (from numba->shap) (59.8.0)\nRequirement already satisfied: llvmlite<0.39,>=0.38.0rc1 in /opt/conda/lib/python3.7/site-packages (from numba->shap) (0.38.0)\nRequirement already satisfied: python-dateutil>=2.7.3 in /opt/conda/lib/python3.7/site-packages (from pandas->shap) (2.8.2)\nRequirement already satisfied: pytz>=2017.3 in /opt/conda/lib/python3.7/site-packages (from pandas->shap) (2022.1)\nRequirement already satisfied: joblib>=0.11 in /opt/conda/lib/python3.7/site-packages (from scikit-learn->shap) (1.1.0)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.7/site-packages (from scikit-learn->shap) (3.1.0)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.7/site-packages (from python-dateutil>=2.7.3->pandas->shap) (1.16.0)\nInstalling collected packages: shap\n  Attempting uninstall: shap\n    Found existing installation: shap 0.40.0\n    Uninstalling shap-0.40.0:\n      Successfully uninstalled shap-0.40.0\nSuccessfully installed shap-0.42.1\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0mNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}],"execution_count":51},{"cell_type":"code","source":"# import shap\n\n# # Now this will work as the model is properly fitted\n# explainer = shap.TreeExplainer(xgb_model)\n# shap_values = explainer.shap_values(X_augmented)\n\n# # Visualize feature impact\n# shap.summary_plot(shap_values, X_augmented, feature_names=X_augmented.columns)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-14T11:09:24.289223Z","iopub.execute_input":"2025-04-14T11:09:24.289727Z","execution_failed":"2025-04-14T12:40:53.355Z"}},"outputs":[{"name":"stderr","text":"ntree_limit is deprecated, use `iteration_range` or model slicing instead.\n","output_type":"stream"}],"execution_count":null},{"cell_type":"code","source":"# import shap\n\n# # Define your feature columns\n# feature_cols = [f'f{i}' for i in range(12)]\n\n# # Sample from the original dataset\n# X_sampled = df[feature_cols].sample(n=1000, random_state=42)\n\n# # Use TreeExplainer for tree-based models like XGBoost\n# explainer = shap.TreeExplainer(learner_s.model)\n\n# # Compute SHAP values\n# shap_values = explainer.shap_values(X_sampled)\n\n# # Summary plot\n# shap.summary_plot(shap_values, X_sampled, feature_names=feature_cols)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-17T17:17:16.810071Z","iopub.execute_input":"2025-04-17T17:17:16.810544Z","iopub.status.idle":"2025-04-17T17:17:18.028407Z","shell.execute_reply.started":"2025-04-17T17:17:16.810507Z","shell.execute_reply":"2025-04-17T17:17:18.027043Z"}},"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNotFittedError\u001b[0m                            Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_17/3518013653.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;31m# Use TreeExplainer for tree-based models like XGBoost\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mexplainer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mshap\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTreeExplainer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlearner_s\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;31m# Compute SHAP values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/shap/explainers/_tree.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, model, data, model_output, feature_perturbation, feature_names, approximate, **deprecated_options)\u001b[0m\n\u001b[1;32m    146\u001b[0m                     \"Please update the option name before calling TreeExplainer. See GitHub issue #882.\")\n\u001b[1;32m    147\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mfeature_perturbation\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"independent\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 148\u001b[0;31m             raise InvalidFeaturePerturbationError(\"feature_perturbation = \\\"independent\\\" is not a valid option value, please use \" \\\n\u001b[0m\u001b[1;32m    149\u001b[0m                 \"feature_perturbation = \\\"interventional\\\" instead. See GitHub issue #882.\")\n\u001b[1;32m    150\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/shap/explainers/_tree.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, model, data, data_missing, model_output)\u001b[0m\n\u001b[1;32m    841\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbase_offset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbase_offset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    842\u001b[0m                 \u001b[0mhas_len\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 843\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0mhas_len\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_output\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m\"raw\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    844\u001b[0m                 emsg = (\n\u001b[1;32m    845\u001b[0m                     \u001b[0;34m\"Multi-output HistGradientBoostingClassifier models are not yet supported unless \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/xgboost/sklearn.py\u001b[0m in \u001b[0;36mget_booster\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    588\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__sklearn_is_fitted__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    589\u001b[0m             \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexceptions\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mNotFittedError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 590\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mNotFittedError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'need to call fit or load_model beforehand'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    591\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_Booster\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    592\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNotFittedError\u001b[0m: need to call fit or load_model beforehand"],"ename":"NotFittedError","evalue":"need to call fit or load_model beforehand","output_type":"error"}],"execution_count":58},{"cell_type":"code","source":"# # Create a per-user SHAP DataFrame\n# import pandas as pd\n\n# shap_df = pd.DataFrame(shap_values, columns=X_augmented.columns)\n# shap_df['predicted_uplift'] = xgb_model.predict(X_augmented)\n# shap_df['user_id'] = X_augmented.index\n\n# # See the top 5 users\n# shap_df.head()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-17T17:10:24.734522Z","iopub.execute_input":"2025-04-17T17:10:24.735031Z","iopub.status.idle":"2025-04-17T17:10:24.776179Z","shell.execute_reply.started":"2025-04-17T17:10:24.734987Z","shell.execute_reply":"2025-04-17T17:10:24.774877Z"}},"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_17/35862982.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mshap_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshap_values\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mX_augmented\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mshap_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'predicted_uplift'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mxgb_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_augmented\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mshap_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'user_id'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX_augmented\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'shap_values' is not defined"],"ename":"NameError","evalue":"name 'shap_values' is not defined","output_type":"error"}],"execution_count":52},{"cell_type":"code","source":"# # Top k features driving the prediction per user\n# shap_df['top_k_features'] = shap_df[X_augmented.columns].abs().apply(\n#     lambda row: row.nlargest(4).index.tolist(), axis=1\n# )\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# import shap\n# import pandas as pd\n\n# # Step 1: Create a SHAP TreeExplainer\n# explainer = shap.TreeExplainer(xgb_model)\n\n# # Step 2: Compute SHAP values for each user (row) and feature\n# shap_values = explainer.shap_values(X_augmented)\n\n# # Step 3: Convert to DataFrame\n# shap_df = pd.DataFrame(shap_values, columns=X_augmented.columns)\n\n# # Step 4: Add predicted uplift as a separate column\n# shap_df['predicted_uplift'] = xgb_model.predict(X_augmented)\n\n# # Step 5: Add unique IDs if not already present\n# shap_df['user_id'] = X_augmented.index\n\n# # Optional: Reorder columns\n# shap_df = shap_df[['user_id', 'predicted_uplift'] + list(X_augmented.columns)]\n\n# # Step 6: View the SHAP contributions for each user\n# print(shap_df.head())\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# import shap\n\n# # Use the fitted XGBoost model directly\n# fitted_model = learner_s.model\n\n# # SHAP TreeExplainer\n# explainer = shap.TreeExplainer(fitted_model)\n\n# # Get SHAP values (this gives you the effect of each feature on the model's prediction)\n# shap_values = explainer.shap_values(X_train)\n\n# # Summary plot to visualize feature impact on the treatment effect\n# shap.summary_plot(shap_values, X_train, feature_names=feature_cols)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"learner_s.plot_importance(X=X_train, tau=learner_s_result, normalize=True, method='auto', features=feature_cols)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-14T10:39:58.509167Z","iopub.execute_input":"2025-04-14T10:39:58.509732Z","iopub.status.idle":"2025-04-14T10:40:26.652911Z","shell.execute_reply.started":"2025-04-14T10:39:58.509691Z","shell.execute_reply":"2025-04-14T10:40:26.651554Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"<Figure size 864x576 with 1 Axes>","image/png":"iVBORw0KGgoAAAANSUhEUgAAAxgAAAIHCAYAAAAcivqeAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8qNh9FAAAACXBIWXMAAAsTAAALEwEAmpwYAAAm3UlEQVR4nO3de5CddX3H8U92A5TCNgcwnIzxQDa4SAIiimZR62JhiBLHIqgFL6MTpOKC2+6oRGBUtF6yFLUXLykYM/WyJqYUBTGDYUw6LHLzgiXSuj32iIViQkRXE7ySTf9wyBChhGR/J+fs5vWa4Y8959nn99vkO8Lb5zz7TBsbG9seAACAAjpavQEAAGDqEBgAAEAxAgMAAChGYAAAAMUIDAAAoBiBAQAAFCMwAACAYgQGAMVce+21ueiii3L66aenVqulUqnk3HPPbfW2ANiLprd6AwBMHVdccUW+973v5eCDD85Tn/rUbNmypdVbAmAvcwUDgGI+9KEP5dvf/nbuvffefOQjH2n1dgBoAVcwACimr6+v1VsAoMVcwQAAAIoRGAAAQDECAwAAKEZgAAAAxQgMAACgGIEBAAAUIzAAAIBiBAYAAFCMB+0BUMz111+fr371q0mSBx54IEnyrW99K/39/TuOWbZsWUv2BsDeMW1sbGx7qzcBwNSwdOnSXH755U94zNjY2N7ZDAAtITAAAIBi3IMBAAAUIzAAAIBiBAYAAFCMwAAAAIoRGAAAQDECAwAAKEZgAAAAxQgMSFKv11u9BfZh5o9WM4O0kvmbegQGAABQjMAAAACKERgAAEAxAgMAAChGYAAAAMUIDAAAoJhpY2Nj21u9iUesaWxp9RYAAKDtLJrb1eotPGmuYAAAAMUIDAAAoBiBAQAAFCMwAACAYooExvj4eAYHB9Pd3Z1KpZKRkZESpwUAACaZIoGxdu3aDA8PZ9WqVRkdHU1vb++O9z760Y+mUqnkoosuKrEUAADQxqaXOEmj0Ui1Wt0pLJLkm9/8Zv75n/85xx57bIllAACANjfhKxj9/f259NJLc99996VSqeSZz3xmkuTnP/95/vIv/zIf//jHU6lUJroMAAAwCUw4MIaGhrJkyZLMnj07o6OjWb9+fZJkcHAwZ5xxRvr6+ia8SQAAYHKY8EekZsyYka6urnR0dKRarSZJPvOZz6TRaOSqq66a8AYBAGBfV6/XW72FHXp6ep7w/SL3YDxavV7P3/zN3+SGG27IfvvtV/r0AACwz9nVf9S3k+KBcccdd+TBBx/MSSedtOO1bdu25ZZbbsmKFSty//3354ADDii9LAAA0AaKB8bLXvayPPvZz97ptQsvvDBHHXVU3va2t2X//fcvvSQAANAmigdGpVJ5zG+N+uM//uMccsghmT9/funlAACANlLkQXsAAABJMm1sbGx7qzfxiDWNLa3eAgAAtJ1Fc7tavYUnzRUMAACgGIEBAAAUIzAAAIBi2uoeDGiVer0+qR5gw9Ri/mg1M0grmb+pxxUMAACgGIEBAAAUIzAAAIBiBAYAAFCMwAAAAIoRGAAAQDECAwAAKEZgAAAAxQgMAACgGIEBAAAUIzAAAIBiBAYAAFCMwAAAAIoRGAAAQDECAwAAKEZgAAAAxQgMAACgGIEBAAAUM73VG3i0NY0trd4C+6rOWambP5pk0dyuVm8BAPYaVzAAAIBiBAYAAFCMwAAAAIoRGAAAQDFFAmN8fDyDg4Pp7u5OpVLJyMhIidMCAACTTJHAWLt2bYaHh7Nq1aqMjo7me9/7Xl7wghekVqulVqvltNNOy9e+9rUSSwEAAG2syK+pbTQaqVar6e3tTZIcccQRed/73pejjjoq4+PjWblyZV73utfl3/7t33LccceVWBIAAGhDEw6M/v7+rFy5MklSqVRSq9WyYcOGnY5597vfnU9/+tP55je/KTAAAGAKm3BgDA0NpVarZXh4OOvWrUtnZ+dO72/bti1f/vKX89BDD2XBggUTXQ4AAGhjEw6MGTNmpKurKx0dHalWqztev/vuu7Nw4cL8+te/zkEHHZTPf/7zOfbYYye6HMCkU6/XixwDzWQGaSXzN7n09PQ84ftF7sH4/xYeGRnJL37xi1x77bXp7+/P9ddfn/nz5zdrSYC2tKv/Ia7X67s8BprJDNJK5m/qaVpg7L///pk7d26S5IQTTsh3vvOdfPKTn8zHP/7xZi0JAAC02F570N74+Hh++9vf7q3lAACAFmjKFYz3vve9WbhwYWbPnp2tW7fm6quvzs0335zVq1c3YzkAAKBNNCUwNm3alDe/+c154IEH8id/8ic59thjc/XVV+fUU09txnIAAECbmDY2Nra91Zt4xJrGllZvAaC4RXO7nvB9NzjSamaQVjJ/U89euwcDAACY+gQGAABQjMAAAACKadpzMPbErj6nDM3i858AAGW4ggEAABQjMAAAgGIEBgAAUIzAAAAAihEYAABAMQIDAAAoRmAAAADFCAwAAKAYgQEAABQjMAAAgGIEBgAAUIzAAAAAihEYAABAMQIDAAAoRmAAAADFCAwAAKAYgQEAABQjMAAAgGKmt3oDj7amsaXVW2ASWDS3q9VbAADg/+EKBgAAUIzAAAAAihEYAABAMQIDAAAo5kkFxvj4eAYHB9Pd3Z1KpZKRkZFm7wsAAJiEnlRgrF27NsPDw1m1alVGR0fT0dGRc845J/PmzUulUsnw8PBjvue6667LWWedlaOOOkqUAADAPuJJBUaj0Ui1Wk1vb2+q1WoeeuihzJ8/P0NDQznwwAMf93t++ctfZsGCBfngBz9YdMMAAED72uVzMPr7+7Ny5cokSaVSSa1Wy4YNG7Jw4cIkyQUXXPC433fOOeckSR588MFSewUAANrcLgNjaGgotVotw8PDWbduXTo7O/fGvgAAgElol4ExY8aMdHV1paOjI9VqdW/sCZ5QvV6fVOeFJ8P80WpmkFYyf5NLT0/PE76/y8CAdrOrod4T9Xq9KeeFJ8P80WpmkFYyf1OP52AAAADFCAwAAKCYPfqI1NatW9NoNJL8/iF89913X+66664ccsghqdVqSZKf/exnuffee/Pzn/88SfLDH/4wM2bMSLVadS8HAABMUXt0BePOO+9MX19f+vr68qtf/SpLly5NX19fPvShD+04Zs2aNenr68vLX/7yJMlf/dVfpa+vLytWrCizcwAAoO1MGxsb297qTTxiTWNLq7fAJLBoblfxc7rBjFYyf7SaGaSVzN/U4x4MAACgGIEBAAAUIzAAAIBi2upBe834bD0AALD3uIIBAAAUIzAAAIBiBAYAAFCMwAAAAIoRGAAAQDECAwAAKEZgAAAAxQgMAACgGIEBAAAUIzAAAIBiBAYAAFCMwAAAAIoRGAAAQDECAwAAKEZgAAAAxQgMAACgGIEBAAAUIzAAAIBiprd6A4+2prGl1Vvg/7FoblertwAAwCTgCgYAAFCMwAAAAIoRGAAAQDECAwAAKKZIYIyPj2dwcDDd3d2pVCoZGRkpcVoAAGCSKRIYa9euzfDwcFatWpXR0dEcf/zxufjii3Pcccdl1qxZWbhwYb7zne+UWAoAAGhjRX5NbaPRSLVaTW9vb5Jk8eLFufvuu7Ns2bLMnj07X/ziF/OKV7wit912W5761KeWWBIAAGhDEw6M/v7+rFy5MklSqVQyc+bM/PSnP81nP/vZvOhFL0qSXHLJJbnhhhuyYsWKvOtd75rokgAAQJuacGAMDQ2lVqtleHg469aty+9+97scd9xx+aM/+qOdjjvwwANz6623TnQ5AACgjU04MGbMmJGurq50dHSkWq0mSRYsWJAPf/jDmTdvXqrVaq6++urccccdmTt37oQ3TGvU6/VWb6Hp9oWfkfZl/mg1M0grmb/Jpaen5wnfL3IPxh+68sorc+GFF2b+/Pnp7OzMs571rLzqVa/Kd7/73WYsx16wq0Ga7Or1+pT/GWlf5o9WM4O0kvmbepryHIzu7u6sWbMm//u//5u77757x0en5syZ04zlAACANtHUB+0ddNBBmTVrVsbGxvL1r389ixYtauZyAABAizXlI1Jf//rXMz4+np6envzwhz/Mu9/97hx99NF53ete14zlAACANtGUwPjFL36R973vfbn//vtzyCGH5M///M/zrne9K/vtt18zlgMAANpEkcAYGBjIwMDAjq/PPPPMnHnmmSVODQAATCJNvQcDAADYtwgMAACgGIEBAAAU05SbvPfUorldrd4CAAAwAa5gAAAAxQgMAACgGIEBAAAUIzAAAIBiBAYAAFCMwAAAAIoRGAAAQDECAwAAKEZgAAAAxQgMAACgGIEBAAAUIzAAAIBiBAYAAFCMwAAAAIoRGAAAQDECAwAAKEZgAAAAxQgMAACgmOmt3sCjrWlsafUW9gmL5na1egsAAExRrmAAAADFCAwAAKAYgQEAABQjMAAAgGKKBcb4+HgGBwfT3d2dSqWSkZGRUqcGAAAmiWKBsXbt2gwPD2fVqlUZHR1Nb29vli9fnuOPPz7VajUnn3xybrnlllLLAQAAbahYYDQajVSr1fT29qZareb666/PxRdfnLe//e256aabsmDBgrz61a/OvffeW2pJAACgzRR5DkZ/f39WrlyZJKlUKqnVajn88MPz2te+Nm984xuTJFdccUW+/vWvZ8WKFbnssstKLAsAALSZIoExNDSUWq2W4eHhrFu3LtOmTcu8efMyMDCw03GnnHJKbr/99hJLAgAAbahIYMyYMSNdXV3p6OhItVrNj3/842zbti0zZ87c6biZM2fmgQceKLEkE1Cv11u9hbbkz4VWMn+0mhmklczf5NLT0/OE7xcJDCaXXQ3Fvqher/tzoWXMH61mBmkl8zf1NOU5GIcddlg6OzuzefPmnV7fvHlzDj/88GYsCQAAtIGmBMb++++fE044IevXr9/p9fXr16e3t7cZSwIAAG2gaR+RuvDCC3P++efnxBNPTG9vb1asWJGNGzdm8eLFzVoSAABosaYFxllnnZWf/vSnueKKK7Jp06bMmzcvq1evzhFHHNGsJQEAgBabNjY2tr3Vm3jEmsaWVm9hn7Boblert9B23GBGK5k/Ws0M0krmb+ppyj0YAADAvklgAAAAxbTVczB8dAcAACY3VzAAAIBiBAYAAFCMwAAAAIoRGAAAQDECAwAAKEZgAAAAxQgMAACgGIEBAAAUIzAAAIBiBAYAAFCMwAAAAIoRGAAAQDECAwAAKEZgAAAAxQgMAACgGIEBAAAUIzAAAIBiBAYAAFCMwAAAAIqZ3uoNPNqaxpZWb6EtLZrb1eotAADAk+IKBgAAUIzAAAAAihEYAABAMQIDAAAopkhgjI+PZ3BwMN3d3alUKhkZGSlxWgAAYJIpEhhr167N8PBwVq1aldHR0XzjG9/In/3Zn6VWq+Woo47K2Wefnf/4j/8osRQAANDGigRGo9FItVpNb29vqtVq7rjjjrzpTW/K1772tVx33XWZPn16XvGKV+RnP/tZieUAAIA2NeHnYPT392flypVJkkqlklqtlg0bNux0zJVXXpkjjjgit912W04//fSJLgkAALSpCQfG0NBQarVahoeHs27dunR2dj7mmK1bt2Z8fDyVSmWiywEAAG1swoExY8aMdHV1paOjI9Vq9XGPufjii/PMZz4zCxYsmOhy+6R6vd7qLewT/DnTSuaPVjODtJL5m1x6enqe8P0JB8auXHrppbnttttyww03PO7VDXZtV3+JTFy9XvfnTMuYP1rNDNJK5m/qaWpgXHLJJbnmmmvyla98JXPmzGnmUgAAQBtoWmC8853vzJe+9KV85StfydFHH92sZQAAgDbSlMB4xzvekS9+8Yv5/Oc/n0qlkk2bNiVJDjrooBx88MHNWBIAAGgDRZ6D8YeWL1+eLVu25IwzzsgznvGMHf987GMfa8ZyAABAmyhyBWNgYCADAwM7vh4bGytxWgAAYJJpyhUMAABg3yQwAACAYpr+HIzdsWhuV6u3AAAATIArGAAAQDECAwAAKEZgAAAAxQgMAACgGIEBAAAUIzAAAIBiBAYAAFCMwAAAAIoRGAAAQDECAwAAKEZgAAAAxQgMAACgGIEBAAAUIzAAAIBiBAYAAFCMwAAAAIoRGAAAQDECAwAAKEZgAAAAxUxv9QYebU1jS6u3sNcsmtvV6i0AAEBxrmAAAADFCAwAAKAYgQEAABTzpAJjfHw8g4OD6e7uTqVSycjISLP3BQAATEJPKjDWrl2b4eHhrFq1KqOjo+no6Mg555yTefPmpVKpZHh4+DHfs3379ixdujTHHHNMZs2alZe97GX5z//8z+I/AAAA0D6eVGA0Go1Uq9X09vamWq3moYceyvz58zM0NJQDDzzwcb/nH/7hH/KJT3wil19+edatW5eZM2fmzDPPzJYt+85vigIAgH3NLn9NbX9/f1auXJkkqVQqqdVq2bBhQxYuXJgkueCCCx7zPdu3b8+yZcsyODiYM844I0mybNmy9PT05Oqrr87ixYtL/gwAAECb2OUVjKGhoSxZsiSzZ8/O6Oho1q9fv8uT/uhHP8qmTZtyyimn7HjtwAMPzAte8ILcfvvtE9sxAADQtnZ5BWPGjBnp6upKR0dHqtXqkzrppk2bkiQzZ87c6fWZM2fmxz/+8R5sc+qp1+ut3gJ/wN8JrWT+aDUzSCuZv8mlp6fnCd9vqyd570t29RfD3lWv1/2d0DLmj1Yzg7SS+Zt6mvIcjEeudGzevHmn1zdv3pzDDz+8GUsCAABtoCmBceSRR6Zare50v8avf/3r3Hrrrent7W3GkgAAQBvYo49Ibd26NY1GI8nvH8J333335a677sohhxySWq2WadOmpb+/Px/96EfT09OTpz/96fnwhz+cgw46KK961auK/gAAAED72KPAuPPOO/Pyl798x9dLly7N0qVL85rXvCbLli1Lkvz1X/91fvWrX+Wiiy7K2NhYTjzxxFxzzTXp6uoqs3MAAKDtTBsbG9ve6k08Yk1j33kI36K5QquduMGMVjJ/tJoZpJXM39TTlHswAACAfZPAAAAAihEYAABAMW31oD33JQAAwOTmCgYAAFCMwAAAAIoRGAAAQDECAwAAKEZgAAAAxQgMAACgGIEBAAAUIzAAAIBiBAYAAFCMwAAAAIoRGAAAQDECAwAAKEZgAAAAxQgMAACgGIEBAAAUIzAAAIBiBAYAAFCMwAAAAIoRGAAAQDHTW72BR1vT2NLqLey2RXO7Wr0FAABoG65gAAAAxQgMAACgGIEBAAAUUyQwxsfHMzg4mO7u7lQqlYyMjJQ4LQAAMMkUCYy1a9dmeHg4q1atyujoaHp7e7Nx48a85S1vyVFHHZVqtZre3t7cfPPNJZYDAADaVJHfItVoNHZERJKMjY3lJS95SU466aSsXr06hx12WH70ox9l5syZJZYDAADa1IQDo7+/PytXrkySVCqV1Gq1vPrVr86sWbNy5ZVX7jhuzpw5E10KAABocxP+iNTQ0FCWLFmS2bNnZ3R0NOvXr89Xv/rVnHjiiVm8eHGe/vSn50//9E9z1VVXZfv27SX2DAAAtKkJX8GYMWNGurq60tHRkWq1miS555578ulPfzoXXHBBBgcHs2HDhrzzne9Mkrz5zW+e6JJtpV6vt3oLFOLvklYyf7SaGaSVzN/k0tPT84TvN+VJ3uPj43n2s5+dyy67LEnyrGc9K41GI8uXL59ygbGrP2Amh3q97u+SljF/tJoZpJXM39TTlOdgVKvVPOMZz9jptaOPPjr33XdfM5YDAADaRFMC46STTsoPfvCDnV77wQ9+kFqt1ozlAACANtGUwLjgggvyzW9+Mx/+8IfTaDTy5S9/OVdddVXOO++8ZiwHAAC0iaYExnOe85wMDw/nS1/6Up7//Ofn/e9/fy699FKBAQAAU1yRm7wHBgYyMDCw02sveclL8pKXvKTE6QEAgEmiKVcwAACAfZPAAAAAihEYAABAMU150N6eWjS3q9VbAAAAJsAVDAAAoBiBAQAAFCMwAACAYgQGAABQjMAAAACKERgAAEAxAgMAAChGYAAAAMUIDAAAoBiBAQAAFCMwAACAYgQGAABQjMAAAACKERgAAEAxAgMAAChGYAAAAMUIDAAAoBiBAQAAFCMwAACAYqa3egOPtqaxpej5Fs3tKno+AADgibmCAQAAFCMwAACAYgQGAABQTJHAGB8fz+DgYLq7u1OpVDIyMlLitAAAwCRTJDDWrl2b4eHhrFq1KqOjo1mwYEE+8IEP5Pjjj0+1Ws3xxx+fD3zgA3n44YdLLAcAALSpIr9FqtFopFqtpre3N0nykY98JMuXL8+yZcsyf/783H333env78/++++fJUuWlFgSAABoQxMOjP7+/qxcuTJJUqlUUqvVMn/+/Lz0pS/N6aefniQ58sgjc/rpp+fb3/72RJcDAADa2IQ/IjU0NJQlS5Zk9uzZGR0dzfr163PSSSfl5ptvzn/9138lSb7//e9nZGQkp5122oQ3DAAAtK8JX8GYMWNGurq60tHRkWq1miQZHBzM1q1b09vbm87Ozjz88MN5xzvekfPOO2/CG94d9Xp9r67H5GZeaCXzR6uZQVrJ/E0uPT09T/h+U57kfc0112TVqlVZvnx5jjnmmGzYsCEXX3xxjjjiiLzhDW9oxpKPa1c/PDyiXq+bF1rG/NFqZpBWMn9TT1MC4z3veU/e+ta35pWvfGWS5Nhjj829996bv/u7v9urgQEAAOxdTXnQ3i9/+ct0dnbu9FpnZ2fGx8ebsRwAANAmmnIF46UvfWn+/u//PkceeWSOOeaY3HXXXfnEJz6Rc845pxnLAQAAbaIpgfG3f/u3+eAHP5i3v/3t+clPfpJqtZo3vvGNnoEBAABT3LSxsbHtrd7EI9Y0thQ936K5XUXPx9TlBjNayfzRamaQVjJ/U09T7sEAAAD2TQIDAAAoRmAAAADFNOUm7z3lngkAAJjcXMEAAACKERgAAEAxAgMAAChGYAAAAMUIDAAAoBiBAQAAFCMwAACAYgQGAABQjMAAAACKERgAAEAxAgMAAChGYAAAAMUIDAAAoBiBAQAAFCMwAACAYgQGAABQjMAAAACKERgAAEAx01u9gUdb09iyx9+7aG5XwZ0AAAB7whUMAACgGIEBAAAUIzAAAIBiBAYAAFBMkcAYHx/P4OBguru7U6lUMjIyUuK0AADAJFMkMNauXZvh4eGsWrUqo6OjWb9+fSqVyk7/HH300SWWAgAA2liRX1PbaDRSrVbT29ubJNlvv/3S09OT66+/fscxnZ2dJZYCAADa2IQDo7+/PytXrkySVCqV1Gq1vPa1r8306dNTrVYnvEEAAGDymPBHpIaGhrJkyZLMnj17x8ejkuSee+7JMccck+OPPz7nnntu7rnnnokuBQAAtLlpY2Nj2yd6ko997GO56qqrsmHDhiTJjTfemK1bt6anpyc/+clPcsUVV6Rer+e2227LoYce+v+eZyJP8u7ZtnGPvxcAAHhyenp6nvD9Ivdg/KHTTjttp6+f+9zn5oQTTsgXvvCFvPWtb23Gkrv8QeGJ1Ot1M0TLmD9azQzSSuZv6tkrz8E4+OCDc8wxx6TRaOyN5QAAgBbZK4Hx61//OvV63U3fAAAwxTXlI1Lvete78tKXvjRPe9rTdtyD8ctf/jKvec1rmrEcAADQJpoSGPfff3/OO++8PPjgg3nKU56S5z73ubnxxhtzxBFHNGM5AACgTRQJjIGBgQwMDOz4esWKFSVOCwAATDJ75R4MAABg3yAwAACAYgQGAABQTFNu8t5Ti+Z2tXoLAADABLiCAQAAFCMwAACAYgQGAABQjMAAAACKERgAAEAxAgMAAChGYAAAAMUIDAAAoBiBAQAAFCMwAACAYgQGAABQjMAAAACKERgAAEAxAgMAAChGYAAAAMUIDAAAoBiBAQAAFCMwAACAYqa3egOPtqaxZbeOXzS3q0k7AQAA9oQrGAAAQDECAwAAKEZgAAAAxQgMAACgmCKBMT4+nsHBwXR3d6dSqWRkZKTEaQEAgEmmyG+RWrt2bYaHh3P99ddnzpw5Ofnkk7Nx48bHHLdw4cKsXr26xJIAAEAbKhIYjUYj1Wo1vb29SZKbb74527Zt2/H+xo0b8+IXvziveMUrSiwHAAC0qQkHRn9/f1auXJkkqVQqqdVq2bBhw07HfO5zn0tXV1fOPPPMiS4HAAC0sQkHxtDQUGq1WoaHh7Nu3bp0dnbu9P727dvzuc99LmeffXYOPPDAiS4HAAC0sQkHxowZM9LV1ZWOjo5Uq9XHvL9+/fr86Ec/yhve8IaJLvUY9Xq9+DnZd5knWsn80WpmkFYyf5NLT0/PE75f5B6MJ/KZz3wmz3nOc/LMZz6z+Ll39cPBk1Wv180TLWP+aDUzSCuZv6mnqc/B2Lx5c9asWZM3vvGNzVwGAABoE00NjC984Qs54IAD8spXvrKZywAAAG2iaYGxffv2fPazn81ZZ52Vgw8+uFnLAAAAbaRpgTEyMpL//u//9vEoAADYhxQJjIGBgcc8+6Kvry9jY2M58cQTSywBAABMAk29BwMAANi3CAwAAKAYgQEAABTT9Aft7Y5Fc7tavQUAAGACXMEAAACKERgAAEAxAgMAAChGYAAAAMUIDAAAoBiBAQAAFCMwAACAYgQGAABQjMAAAACKERgAAEAxAgMAAChGYAAAAMUIDAAAoBiBAQAAFCMwAACAYgQGAABQjMAAAACKERgAAEAx01u9gUdb09jypI5bNLeryTsBAAD2hCsYAABAMQIDAAAoRmAAAADFCAwAAKCYIoExPj6ewcHBdHd3p1KpZGRkpMRpAQCASaZIYKxduzbDw8NZtWpVRkdH09HRkXPOOSfz5s1LpVLJ8PBwiWUAAIA2VyQwGo1GqtVqent7U61W89BDD2X+/PkZGhrKgQceWGIJAABgEpjwczD6+/uzcuXKJEmlUkmtVsuGDRuycOHCJMkFF1ww0SUAAIBJYsKBMTQ0lFqtluHh4axbty6dnZ0l9gUAAExCEw6MGTNmpKurKx0dHalWqyX2tEv1en2vrMO+xVzRSuaPVjODtJL5m1x6enqe8P0JB0Yr7OqHgt1Vr9fNFS1j/mg1M0grmb+px3MwAACAYgQGAABQTFM+IrV169Y0Go0kv38I33333Ze77rorhxxySGq1WjOWBAAA2kBTrmDceeed6evrS19fX371q19l6dKl6evry4c+9KFmLAcAALSJIlcwBgYGMjAwsOPrF73oRRkbGytxagAAYBJxDwYAAFCMwAAAAIoRGAAAQDFt9aC9RXO7Wr0FAABgAlzBAAAAihEYAABAMQIDAAAoRmAAAADFCAwAAKAYgQEAABQjMAAAgGKmjY2NbW/1JgAAgKnBFQwAAKAYgQEAABQjMAAAgGIEBgAAUIzAAAAAitkrgbF8+fIcf/zxqVarOfnkk3PLLbc84fE333xzTj755FSr1TzrWc/KihUr9sY2mcJ2ZwY3btyY8847L8973vNy6KGHpr+/fy/ulKlod+bvuuuuy5lnnpmjjjoqT3va03LqqadmzZo1e3G3TEW7M4M333xzFi5cmO7u7syaNSvPe97z8rGPfWwv7papZnf/O/ARt956aw477LA8//nPb/IOKa3pgXHNNdfk4osvztvf/vbcdNNNWbBgQV796lfn3nvvfdzj77nnnvzFX/xFFixYkJtuuilve9vbsmTJklx77bXN3ipT1O7O4G9+85sceuihGRwczHOf+9y9vFummt2dv2984xvp6+vL6tWrc9NNN+W0007L61//+if9L2T4Q7s7gwcffHDOP//8rFmzJrfddlve8Y53ZOnSpVm+fPle3jlTwe7O3yPGxsbylre8JSeffPJe2iklNf05GKeeemqOPfbY/OM//uOO157znOfkjDPOyGWXXfaY4y+77LJ85StfyXe+850drw0MDOT73/9+brzxxmZulSlqd2fw0c4+++wceuihWbZsWbO3yRQ1kfl7xCmnnJLnP//5+eAHP9isbTKFlZjB17/+9TnggAPy6U9/ulnbZIra0/l7/etfn+OOOy7bt2/Pddddl1tvvXVvbJdCmnoF47e//W2++93v5pRTTtnp9VNOOSW33377437PHXfc8ZjjTz311Nx555353e9+17S9MjXtyQxCKaXmb+vWralUKoV3x76gxAz++7//e+6444688IUvbMYWmcL2dP6WL1+ezZs356KLLmr2FmmS6c08+YMPPpht27Zl5syZO70+c+bMPPDAA4/7PQ888EBe/OIXP+b4hx9+OA8++GBmzZrVrO0yBe3JDEIpJebvU5/6VO6///6cffbZzdgiU9xEZnD+/Pn5yU9+kocffjjvfOc7c+655zZzq0xBezJ/d999dy6//PLceOON6ezs3BvbpAmaGhgA7Llrr70273nPe7JixYocccQRrd4O+5g1a9bkoYceyre+9a1cdtllOfLII3POOee0eltMYb/5zW9y7rnn5v3vf3/mzJnT6u0wAU0NjMMOOyydnZ3ZvHnzTq9v3rw5hx9++ON+z+GHH/64x0+fPj2HHXZY0/bK1LQnMwilTGT+rr322rzlLW/JP/3TP+X0009v5jaZwiYyg4/8B96xxx6bBx54IENDQwKD3bK787dx48aMjo7mwgsvzIUXXpgkGR8fz/bt23PYYYflX/7lXx7zcSvaU1Pvwdh///1zwgknZP369Tu9vn79+vT29j7u9yxYsOBxj3/2s5+d/fbbr2l7ZWrakxmEUvZ0/r70pS/l/PPPzyc/+cmcccYZzd4mU1ip/w0cHx/Pb3/729LbY4rb3fl76lOfmltuuSUjIyM7/jn33HMzd+7cjIyMZMGCBXtr60xQ0z8ideGFF+b888/PiSeemN7e3qxYsSIbN27M4sWLkyTnn39+kuTKK69MkixevDif+tSncvHFF2fx4sW5/fbb84UvfMGvx2OP7e4MJsldd92VJPnFL36RadOm5a677sr++++fY445Zu//AExquzt///qv/5rzzz8/73//+/OCF7wgmzZtSvL7f1EfcsghrfkhmNR2dwavvPLKHHnkkenp6Uny+1+d/PGPfzxvetObWvMDMKntzvztt99+mT9//k7f/5SnPCUHHHDAY16nvTU9MM4666z89Kc/zRVXXJFNmzZl3rx5Wb169Y7PE9933307HT9nzpysXr06l156aVasWJFZs2bl8ssv9//iscd2dwaTpK+vb6evb7jhhtRqtWzYsGGv7JmpY3fnb8WKFXn44YdzySWX5JJLLtnx+gtf+MJ89atf3at7Z2rY3Rnctm1b3vve9+Z//ud/Mn369MyZMyeXXXaZm7zZI3vy72Amv6Y/BwMAANh3NP1J3gAAwL5DYAAAAMUIDAAAoBiBAQAAFCMwAACAYgQGAABQjMAAAACKERgAAEAxAgMAACjm/wD0V+18HrUDJQAAAABJRU5ErkJggg==\n"},"metadata":{}}],"execution_count":29},{"cell_type":"code","source":"# from sklearn.neural_network import MLPRegressor\n# from causalml.inference.meta import BaseSRegressor\n\n# # Define the neural network regressor\n# nn = MLPRegressor(hidden_layer_sizes=(35, 25, 10, 5),\n#                   learning_rate_init=0.01,\n#                   early_stopping=True,\n#                   random_state=1)","metadata":{"trusted":true,"execution":{"execution_failed":"2025-04-14T12:40:53.355Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# from sklearn.neural_network import MLPRegressor\n# from causalml.inference.meta import BaseSRegressor\n\n# # Define your neural network estimator\n# nn = MLPRegressor(hidden_layer_sizes=(35, 25, 10, 5),\n#                   learning_rate_init=0.01,\n#                   early_stopping=True,\n#                   random_state=1)\n\n# # Plug it into the S-Learner\n# learner_s = BaseSRegressor(learner=nn)\n\n# # Compute ITE estimates for each observation in X_train\n# nn_ite = learner_s.fit_predict(X=X_train, treatment=t_train, y=y_train)\n\n# # Print first few ITE estimates for inspection\n# print(\"Estimated ITE via neural network S-Learner:\")\n# print(nn_ite[:5])\n","metadata":{"trusted":true,"execution":{"execution_failed":"2025-04-14T12:40:53.355Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# import pandas as pd\n# from sklearn.inspection import permutation_importance\n# from sklearn.neural_network import MLPRegressor\n# from causalml.inference.meta import BaseSRegressor\n\n# # # Define the neural network regressor\n# # nn = MLPRegressor(hidden_layer_sizes=(35, 25, 10, 5),\n# #                   learning_rate_init=0.01,\n# #                   early_stopping=True,\n# #                   random_state=1)\n\n# # # Plug it into the S-Learner\n# # learner_s = BaseSRegressor(learner=nn)\n# # learner_s_result = learner_s.fit_predict(X=X_train, treatment=t_train, y=y_train)\n\n# # Compute permutation feature importance on the neural network model\n# # result = permutation_importance(nn, X_train, y_train, n_repeats=10, random_state=42)\n# result = permutation_importance(learner_s.model, X_train, y_train, n_repeats=10, random_state=42)\n\n# result\n","metadata":{"trusted":true,"execution":{"execution_failed":"2025-04-14T12:40:53.355Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"feature_results = result[1]\nfeature_results","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-14T10:24:55.568992Z","iopub.execute_input":"2025-04-14T10:24:55.569441Z","iopub.status.idle":"2025-04-14T10:24:55.584943Z","shell.execute_reply.started":"2025-04-14T10:24:55.569405Z","shell.execute_reply":"2025-04-14T10:24:55.583571Z"}},"outputs":[{"execution_count":23,"output_type":"execute_result","data":{"text/plain":"f4     0.446077\nf3     0.194586\nf11    0.087215\nf9     0.065065\nf0     0.056892\nf2     0.044279\nf10    0.037780\nf6     0.028997\nf8     0.013343\nf5     0.010116\nf7     0.008173\nf1     0.007478\ndtype: float64"},"metadata":{}}],"execution_count":23},{"cell_type":"code","source":"feature_results = feature_results/feature_results.sum() * 100\nfeature_results","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-14T10:25:00.610794Z","iopub.execute_input":"2025-04-14T10:25:00.611230Z","iopub.status.idle":"2025-04-14T10:25:00.623596Z","shell.execute_reply.started":"2025-04-14T10:25:00.611193Z","shell.execute_reply":"2025-04-14T10:25:00.622525Z"}},"outputs":[{"execution_count":24,"output_type":"execute_result","data":{"text/plain":"f4     44.607747\nf3     19.458561\nf11     8.721534\nf9      6.506494\nf0      5.689237\nf2      4.427859\nf10     3.777985\nf6      2.899658\nf8      1.334262\nf5      1.011587\nf7      0.817313\nf1      0.747763\ndtype: float64"},"metadata":{}}],"execution_count":24},{"cell_type":"code","source":"import pickle\n# Save the entire model (including its weights) to a checkpoint file\ncheckpoint_filename = \"synapses_checkpint.pkt\"\nwith open(checkpoint_filename, \"wb\") as f:\n    pickle.dump(nn, f)\n\nprint(f\"Model checkpoint saved to {checkpoint_filename}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-14T10:25:05.062213Z","iopub.execute_input":"2025-04-14T10:25:05.063463Z","iopub.status.idle":"2025-04-14T10:25:05.076044Z","shell.execute_reply.started":"2025-04-14T10:25:05.063104Z","shell.execute_reply":"2025-04-14T10:25:05.074465Z"}},"outputs":[{"name":"stdout","text":"Model checkpoint saved to synapses_checkpint.pkt\n","output_type":"stream"}],"execution_count":25},{"cell_type":"code","source":"# dir(nn)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-13T20:08:23.999658Z","iopub.status.idle":"2025-04-13T20:08:24.000087Z","shell.execute_reply.started":"2025-04-13T20:08:23.999902Z","shell.execute_reply":"2025-04-13T20:08:23.999921Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Looks like the most effective uplift method for this dataset (from tested here) is uplift tree with overall uplift 0.03 (0.031 for top 30%). Among meta learners S-Learners perform better than T-Learners (with a S-Learner based on LGBMClassifier as a leader).","metadata":{}}]}